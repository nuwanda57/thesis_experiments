{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vae_exp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yakOCWTjeWm6",
        "outputId": "d5384113-b027-4bc2-d7a0-85f8ea3c486b"
      },
      "source": [
        "! rm -rf thesis_experiments\n",
        "!git clone https://github.com/nuwanda57/thesis_experiments"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'thesis_experiments'...\n",
            "remote: Enumerating objects: 214, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/214)\u001b[K\rremote: Counting objects:   1% (3/214)\u001b[K\rremote: Counting objects:   2% (5/214)\u001b[K\rremote: Counting objects:   3% (7/214)\u001b[K\rremote: Counting objects:   4% (9/214)\u001b[K\rremote: Counting objects:   5% (11/214)\u001b[K\rremote: Counting objects:   6% (13/214)\u001b[K\rremote: Counting objects:   7% (15/214)\u001b[K\rremote: Counting objects:   8% (18/214)\u001b[K\rremote: Counting objects:   9% (20/214)\u001b[K\rremote: Counting objects:  10% (22/214)\u001b[K\rremote: Counting objects:  11% (24/214)\u001b[K\rremote: Counting objects:  12% (26/214)\u001b[K\rremote: Counting objects:  13% (28/214)\u001b[K\rremote: Counting objects:  14% (30/214)\u001b[K\rremote: Counting objects:  15% (33/214)\u001b[K\rremote: Counting objects:  16% (35/214)\u001b[K\rremote: Counting objects:  17% (37/214)\u001b[K\rremote: Counting objects:  18% (39/214)\u001b[K\rremote: Counting objects:  19% (41/214)\u001b[K\rremote: Counting objects:  20% (43/214)\u001b[K\rremote: Counting objects:  21% (45/214)\u001b[K\rremote: Counting objects:  22% (48/214)\u001b[K\rremote: Counting objects:  23% (50/214)\u001b[K\rremote: Counting objects:  24% (52/214)\u001b[K\rremote: Counting objects:  25% (54/214)\u001b[K\rremote: Counting objects:  26% (56/214)\u001b[K\rremote: Counting objects:  27% (58/214)\u001b[K\rremote: Counting objects:  28% (60/214)\u001b[K\rremote: Counting objects:  29% (63/214)\u001b[K\rremote: Counting objects:  30% (65/214)\u001b[K\rremote: Counting objects:  31% (67/214)\u001b[K\rremote: Counting objects:  32% (69/214)\u001b[K\rremote: Counting objects:  33% (71/214)\u001b[K\rremote: Counting objects:  34% (73/214)\u001b[K\rremote: Counting objects:  35% (75/214)\u001b[K\rremote: Counting objects:  36% (78/214)\u001b[K\rremote: Counting objects:  37% (80/214)\u001b[K\rremote: Counting objects:  38% (82/214)\u001b[K\rremote: Counting objects:  39% (84/214)\u001b[K\rremote: Counting objects:  40% (86/214)\u001b[K\rremote: Counting objects:  41% (88/214)\u001b[K\rremote: Counting objects:  42% (90/214)\u001b[K\rremote: Counting objects:  43% (93/214)\u001b[K\rremote: Counting objects:  44% (95/214)\u001b[K\rremote: Counting objects:  45% (97/214)\u001b[K\rremote: Counting objects:  46% (99/214)\u001b[K\rremote: Counting objects:  47% (101/214)\u001b[K\rremote: Counting objects:  48% (103/214)\u001b[K\rremote: Counting objects:  49% (105/214)\u001b[K\rremote: Counting objects:  50% (107/214)\u001b[K\rremote: Counting objects:  51% (110/214)\u001b[K\rremote: Counting objects:  52% (112/214)\u001b[K\rremote: Counting objects:  53% (114/214)\u001b[K\rremote: Counting objects:  54% (116/214)\u001b[K\rremote: Counting objects:  55% (118/214)\u001b[K\rremote: Counting objects:  56% (120/214)\u001b[K\rremote: Counting objects:  57% (122/214)\u001b[K\rremote: Counting objects:  58% (125/214)\u001b[K\rremote: Counting objects:  59% (127/214)\u001b[K\rremote: Counting objects:  60% (129/214)\u001b[K\rremote: Counting objects:  61% (131/214)\u001b[K\rremote: Counting objects:  62% (133/214)\u001b[K\rremote: Counting objects:  63% (135/214)\u001b[K\rremote: Counting objects:  64% (137/214)\u001b[K\rremote: Counting objects:  65% (140/214)\u001b[K\rremote: Counting objects:  66% (142/214)\u001b[K\rremote: Counting objects:  67% (144/214)\u001b[K\rremote: Counting objects:  68% (146/214)\u001b[K\rremote: Counting objects:  69% (148/214)\u001b[K\rremote: Counting objects:  70% (150/214)\u001b[K\rremote: Counting objects:  71% (152/214)\u001b[K\rremote: Counting objects:  72% (155/214)\u001b[K\rremote: Counting objects:  73% (157/214)\u001b[K\rremote: Counting objects:  74% (159/214)\u001b[K\rremote: Counting objects:  75% (161/214)\u001b[K\rremote: Counting objects:  76% (163/214)\u001b[K\rremote: Counting objects:  77% (165/214)\u001b[K\rremote: Counting objects:  78% (167/214)\u001b[K\rremote: Counting objects:  79% (170/214)\u001b[K\rremote: Counting objects:  80% (172/214)\u001b[K\rremote: Counting objects:  81% (174/214)\u001b[K\rremote: Counting objects:  82% (176/214)\u001b[K\rremote: Counting objects:  83% (178/214)\u001b[K\rremote: Counting objects:  84% (180/214)\u001b[K\rremote: Counting objects:  85% (182/214)\u001b[K\rremote: Counting objects:  86% (185/214)\u001b[K\rremote: Counting objects:  87% (187/214)\u001b[K\rremote: Counting objects:  88% (189/214)\u001b[K\rremote: Counting objects:  89% (191/214)\u001b[K\rremote: Counting objects:  90% (193/214)\u001b[K\rremote: Counting objects:  91% (195/214)\u001b[K\rremote: Counting objects:  92% (197/214)\u001b[K\rremote: Counting objects:  93% (200/214)\u001b[K\rremote: Counting objects:  94% (202/214)\u001b[K\rremote: Counting objects:  95% (204/214)\u001b[K\rremote: Counting objects:  96% (206/214)\u001b[K\rremote: Counting objects:  97% (208/214)\u001b[K\rremote: Counting objects:  98% (210/214)\u001b[K\rremote: Counting objects:  99% (212/214)\u001b[K\rremote: Counting objects: 100% (214/214)\u001b[K\rremote: Counting objects: 100% (214/214), done.\u001b[K\n",
            "remote: Compressing objects: 100% (138/138), done.\u001b[K\n",
            "remote: Total 214 (delta 125), reused 148 (delta 66), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (214/214), 364.78 KiB | 8.68 MiB/s, done.\n",
            "Resolving deltas: 100% (125/125), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vs4eQsLSacfz",
        "outputId": "75948b93-9929-4f4c-c0bb-432aac249e4f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wIahiP1g58a",
        "outputId": "a5b8c3ba-9d9a-4bb4-deb2-5a1cfc0c4dad"
      },
      "source": [
        "%cd thesis_experiments"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/thesis_experiments\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKNtOX-qls-h"
      },
      "source": [
        "!python data_generator/formulas_dataset_generator.py --filenames formulas_train_5_10.txt formulas_val_5_10.txt formulas_test_5_10.txt --counts 20000 10000 10000"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcI6SAgdhLi5"
      },
      "source": [
        "TRAIN_FILE = 'formulas_train_5_10.txt'\n",
        "VAL_FILE = 'formulas_val_5_10.txt'\n",
        "TEST_FILE = 'formulas_test_5_10.txt'\n",
        "from formulas_vae import experiments\n",
        "import formulas_vae.model as my_model\n",
        "\n",
        "import torch"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2bQhSQnld2u",
        "outputId": "8c72349f-fc9e-4916-d532-33b64227fb50"
      },
      "source": [
        "epochs = 3000\n",
        "model_params = {'token_embedding_dim':128, 'hidden_dim':128,\n",
        "        'encoder_layers_cnt':1, 'decoder_layers_cnt':1, 'latent_dim':8}\n",
        "\n",
        "experiments.reconstruct_test_per_epoch(\n",
        "    TRAIN_FILE, VAL_FILE, TEST_FILE, 'mu', 50, epochs, '/content/drive/My Drive/exp_results_no_train_update', model_params, 25)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/thesis_experiments/formulas_vae/model.py:93: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  nn.init.xavier_uniform(p)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 65.377, rec loss: 65.377, kl: 31.927\n",
            "\t[validation] loss: 39.305, rec loss: 39.305, kl: 60.156\n",
            "Epoch 2\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 31.152, rec loss: 31.152, kl: 70.940\n",
            "\t[validation] loss: 26.282, rec loss: 26.282, kl: 76.061\n",
            "Epoch 3\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 24.909, rec loss: 24.909, kl: 73.831\n",
            "\t[validation] loss: 22.973, rec loss: 22.973, kl: 66.123\n",
            "Epoch 4\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 22.581, rec loss: 22.581, kl: 67.810\n",
            "\t[validation] loss: 21.221, rec loss: 21.221, kl: 58.857\n",
            "Epoch 5\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 21.138, rec loss: 21.138, kl: 62.837\n",
            "\t[validation] loss: 20.401, rec loss: 20.401, kl: 64.573\n",
            "Epoch 6\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 20.337, rec loss: 20.337, kl: 57.006\n",
            "\t[validation] loss: 19.471, rec loss: 19.471, kl: 56.741\n",
            "Epoch 7\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 19.426, rec loss: 19.426, kl: 54.483\n",
            "\t[validation] loss: 18.344, rec loss: 18.344, kl: 54.439\n",
            "Epoch 8\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 18.899, rec loss: 18.899, kl: 52.235\n",
            "\t[validation] loss: 18.112, rec loss: 18.112, kl: 51.119\n",
            "Epoch 9\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 18.236, rec loss: 18.236, kl: 50.317\n",
            "\t[validation] loss: 17.433, rec loss: 17.433, kl: 50.586\n",
            "Epoch 10\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 17.815, rec loss: 17.815, kl: 49.781\n",
            "\t[validation] loss: 17.005, rec loss: 17.005, kl: 54.373\n",
            "Epoch 11\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 17.364, rec loss: 17.364, kl: 49.270\n",
            "\t[validation] loss: 16.830, rec loss: 16.830, kl: 50.886\n",
            "Epoch 12\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 16.835, rec loss: 16.835, kl: 49.152\n",
            "\t[validation] loss: 16.188, rec loss: 16.188, kl: 49.754\n",
            "Epoch 13\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 17.006, rec loss: 17.006, kl: 47.311\n",
            "\t[validation] loss: 16.152, rec loss: 16.152, kl: 49.927\n",
            "Epoch 14\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 16.073, rec loss: 16.073, kl: 46.633\n",
            "\t[validation] loss: 15.819, rec loss: 15.819, kl: 51.794\n",
            "Epoch 15\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 15.815, rec loss: 15.815, kl: 47.846\n",
            "\t[validation] loss: 14.995, rec loss: 14.995, kl: 51.700\n",
            "Epoch 16\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 15.159, rec loss: 15.159, kl: 49.872\n",
            "\t[validation] loss: 14.648, rec loss: 14.648, kl: 49.019\n",
            "Epoch 17\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 14.707, rec loss: 14.707, kl: 49.948\n",
            "\t[validation] loss: 14.405, rec loss: 14.405, kl: 52.459\n",
            "Epoch 18\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 15.196, rec loss: 15.196, kl: 48.404\n",
            "\t[validation] loss: 14.176, rec loss: 14.176, kl: 46.192\n",
            "Epoch 19\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 14.127, rec loss: 14.127, kl: 48.035\n",
            "\t[validation] loss: 13.684, rec loss: 13.684, kl: 48.498\n",
            "Epoch 20\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 14.389, rec loss: 14.389, kl: 48.424\n",
            "\t[validation] loss: 14.552, rec loss: 14.552, kl: 52.065\n",
            "Epoch 21\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 13.835, rec loss: 13.835, kl: 48.486\n",
            "\t[validation] loss: 13.241, rec loss: 13.241, kl: 48.895\n",
            "Epoch 22\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 13.655, rec loss: 13.655, kl: 47.359\n",
            "\t[validation] loss: 13.098, rec loss: 13.098, kl: 43.263\n",
            "Epoch 23\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 13.105, rec loss: 13.105, kl: 44.382\n",
            "\t[validation] loss: 12.637, rec loss: 12.637, kl: 45.703\n",
            "Epoch 24\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 12.513, rec loss: 12.513, kl: 45.613\n",
            "\t[validation] loss: 15.163, rec loss: 15.163, kl: 45.777\n",
            "Epoch 25\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 12.823, rec loss: 12.823, kl: 45.528\n",
            "\t[validation] loss: 11.738, rec loss: 11.738, kl: 47.224\n",
            "Epoch 26\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 11.994, rec loss: 11.994, kl: 46.160\n",
            "\t[validation] loss: 11.372, rec loss: 11.372, kl: 46.579\n",
            "Epoch 27\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 11.764, rec loss: 11.764, kl: 46.006\n",
            "\t[validation] loss: 11.408, rec loss: 11.408, kl: 46.379\n",
            "Epoch 28\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 12.435, rec loss: 12.435, kl: 46.091\n",
            "\t[validation] loss: 11.157, rec loss: 11.157, kl: 46.784\n",
            "Epoch 29\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 11.417, rec loss: 11.417, kl: 46.519\n",
            "\t[validation] loss: 10.779, rec loss: 10.779, kl: 47.183\n",
            "Epoch 30\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 10.981, rec loss: 10.981, kl: 46.652\n",
            "\t[validation] loss: 10.426, rec loss: 10.426, kl: 46.893\n",
            "Epoch 31\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 10.749, rec loss: 10.749, kl: 45.986\n",
            "\t[validation] loss: 10.089, rec loss: 10.089, kl: 46.518\n",
            "Epoch 32\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 10.520, rec loss: 10.520, kl: 46.286\n",
            "\t[validation] loss: 9.712, rec loss: 9.712, kl: 47.484\n",
            "Epoch 33\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 9.922, rec loss: 9.922, kl: 47.012\n",
            "\t[validation] loss: 9.440, rec loss: 9.440, kl: 47.600\n",
            "Epoch 34\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 10.453, rec loss: 10.453, kl: 46.684\n",
            "\t[validation] loss: 13.194, rec loss: 13.194, kl: 44.922\n",
            "Epoch 35\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 10.256, rec loss: 10.256, kl: 43.246\n",
            "\t[validation] loss: 9.141, rec loss: 9.141, kl: 44.688\n",
            "Epoch 36\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 9.466, rec loss: 9.466, kl: 44.362\n",
            "\t[validation] loss: 8.661, rec loss: 8.661, kl: 45.101\n",
            "Epoch 37\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 9.422, rec loss: 9.422, kl: 45.346\n",
            "\t[validation] loss: 8.597, rec loss: 8.597, kl: 45.900\n",
            "Epoch 38\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 8.833, rec loss: 8.833, kl: 46.051\n",
            "\t[validation] loss: 8.140, rec loss: 8.140, kl: 46.648\n",
            "Epoch 39\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 8.618, rec loss: 8.618, kl: 46.541\n",
            "\t[validation] loss: 7.875, rec loss: 7.875, kl: 46.650\n",
            "Epoch 40\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 8.430, rec loss: 8.430, kl: 46.421\n",
            "\t[validation] loss: 7.711, rec loss: 7.711, kl: 46.769\n",
            "Epoch 41\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 8.404, rec loss: 8.404, kl: 46.074\n",
            "\t[validation] loss: 7.396, rec loss: 7.396, kl: 46.265\n",
            "Epoch 42\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 8.428, rec loss: 8.428, kl: 45.479\n",
            "\t[validation] loss: 7.270, rec loss: 7.270, kl: 46.976\n",
            "Epoch 43\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 8.000, rec loss: 8.000, kl: 45.934\n",
            "\t[validation] loss: 7.175, rec loss: 7.175, kl: 45.542\n",
            "Epoch 44\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 7.775, rec loss: 7.775, kl: 46.019\n",
            "\t[validation] loss: 7.050, rec loss: 7.050, kl: 46.482\n",
            "Epoch 45\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 7.610, rec loss: 7.610, kl: 46.228\n",
            "\t[validation] loss: 6.833, rec loss: 6.833, kl: 46.615\n",
            "Epoch 46\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 7.224, rec loss: 7.224, kl: 46.732\n",
            "\t[validation] loss: 6.818, rec loss: 6.818, kl: 47.813\n",
            "Epoch 47\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 7.425, rec loss: 7.425, kl: 46.406\n",
            "\t[validation] loss: 7.236, rec loss: 7.236, kl: 47.631\n",
            "Epoch 48\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 6.991, rec loss: 6.991, kl: 46.663\n",
            "\t[validation] loss: 7.292, rec loss: 7.292, kl: 46.078\n",
            "Epoch 49\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 6.958, rec loss: 6.958, kl: 46.887\n",
            "\t[validation] loss: 6.055, rec loss: 6.055, kl: 46.728\n",
            "Epoch 50\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 7.174, rec loss: 7.174, kl: 46.697\n",
            "\t[validation] loss: 6.540, rec loss: 6.540, kl: 46.951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/thesis_experiments/formulas_vae/model.py:162: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  logits, hidden = self.decode(x, torch.tensor(z, device=self.device), hidden)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Epoch 1751\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 57.527\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 57.714\n",
            "Epoch 1752\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 57.548\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 57.786\n",
            "Epoch 1753\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.035, rec loss: 0.035, kl: 57.623\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 57.865\n",
            "Epoch 1754\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 57.709\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 57.867\n",
            "Epoch 1755\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 57.713\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 57.923\n",
            "Epoch 1756\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 57.751\n",
            "\t[validation] loss: 0.136, rec loss: 0.136, kl: 58.038\n",
            "Epoch 1757\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.306, rec loss: 1.306, kl: 57.961\n",
            "\t[validation] loss: 1.792, rec loss: 1.792, kl: 58.601\n",
            "Epoch 1758\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.350, rec loss: 0.350, kl: 58.304\n",
            "\t[validation] loss: 0.201, rec loss: 0.201, kl: 58.348\n",
            "Epoch 1759\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.063, rec loss: 0.063, kl: 58.181\n",
            "\t[validation] loss: 0.172, rec loss: 0.172, kl: 58.243\n",
            "Epoch 1760\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.047, rec loss: 0.047, kl: 58.109\n",
            "\t[validation] loss: 0.137, rec loss: 0.137, kl: 58.195\n",
            "Epoch 1761\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.043, rec loss: 0.043, kl: 58.124\n",
            "\t[validation] loss: 0.137, rec loss: 0.137, kl: 58.321\n",
            "Epoch 1762\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.040, rec loss: 0.040, kl: 58.151\n",
            "\t[validation] loss: 0.122, rec loss: 0.122, kl: 58.257\n",
            "Epoch 1763\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 58.165\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 58.334\n",
            "Epoch 1764\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 58.221\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 58.302\n",
            "Epoch 1765\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 58.228\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 58.389\n",
            "Epoch 1766\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.172, rec loss: 1.172, kl: 58.207\n",
            "\t[validation] loss: 0.257, rec loss: 0.257, kl: 57.994\n",
            "Epoch 1767\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.099, rec loss: 0.099, kl: 57.909\n",
            "\t[validation] loss: 0.155, rec loss: 0.155, kl: 58.003\n",
            "Epoch 1768\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.047, rec loss: 0.047, kl: 57.917\n",
            "\t[validation] loss: 0.162, rec loss: 0.162, kl: 58.033\n",
            "Epoch 1769\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.042, rec loss: 0.042, kl: 57.894\n",
            "\t[validation] loss: 0.127, rec loss: 0.127, kl: 58.047\n",
            "Epoch 1770\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.036, rec loss: 0.036, kl: 57.944\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 58.059\n",
            "Epoch 1771\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 57.993\n",
            "\t[validation] loss: 0.154, rec loss: 0.154, kl: 58.190\n",
            "Epoch 1772\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.191, rec loss: 1.191, kl: 58.422\n",
            "\t[validation] loss: 0.232, rec loss: 0.232, kl: 58.316\n",
            "Epoch 1773\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.079, rec loss: 0.079, kl: 58.288\n",
            "\t[validation] loss: 0.163, rec loss: 0.163, kl: 58.290\n",
            "Epoch 1774\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.048, rec loss: 0.048, kl: 58.309\n",
            "\t[validation] loss: 0.147, rec loss: 0.147, kl: 58.354\n",
            "Epoch 1775\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.042, rec loss: 0.042, kl: 58.298\n",
            "\t[validation] loss: 0.136, rec loss: 0.136, kl: 58.316\n",
            "Epoch 1776\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.037, rec loss: 0.037, kl: 58.314\n",
            "\t[validation] loss: 0.142, rec loss: 0.142, kl: 58.325\n",
            "Epoch 1777\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.035, rec loss: 0.035, kl: 58.333\n",
            "\t[validation] loss: 0.126, rec loss: 0.126, kl: 58.422\n",
            "Epoch 1778\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 58.389\n",
            "\t[validation] loss: 0.122, rec loss: 0.122, kl: 58.394\n",
            "Epoch 1779\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.803, rec loss: 0.803, kl: 58.223\n",
            "\t[validation] loss: 0.308, rec loss: 0.308, kl: 58.078\n",
            "Epoch 1780\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.076, rec loss: 0.076, kl: 57.973\n",
            "\t[validation] loss: 0.155, rec loss: 0.155, kl: 58.107\n",
            "Epoch 1781\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.045, rec loss: 0.045, kl: 57.991\n",
            "\t[validation] loss: 0.129, rec loss: 0.129, kl: 58.064\n",
            "Epoch 1782\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.038, rec loss: 0.038, kl: 58.005\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 58.118\n",
            "Epoch 1783\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.035, rec loss: 0.035, kl: 58.012\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 58.101\n",
            "Epoch 1784\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 58.034\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 58.130\n",
            "Epoch 1785\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 58.078\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 58.201\n",
            "Epoch 1786\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 58.117\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 58.256\n",
            "Epoch 1787\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 58.196\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 58.312\n",
            "Epoch 1788\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 58.146\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 58.258\n",
            "Epoch 1789\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 58.201\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 58.264\n",
            "Epoch 1790\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.721, rec loss: 0.721, kl: 58.399\n",
            "\t[validation] loss: 2.070, rec loss: 2.070, kl: 58.884\n",
            "Epoch 1791\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.891, rec loss: 0.891, kl: 58.683\n",
            "\t[validation] loss: 0.339, rec loss: 0.339, kl: 58.368\n",
            "Epoch 1792\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.080, rec loss: 0.080, kl: 58.312\n",
            "\t[validation] loss: 0.173, rec loss: 0.173, kl: 58.256\n",
            "Epoch 1793\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.047, rec loss: 0.047, kl: 58.200\n",
            "\t[validation] loss: 0.140, rec loss: 0.140, kl: 58.274\n",
            "Epoch 1794\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.038, rec loss: 0.038, kl: 58.210\n",
            "\t[validation] loss: 0.129, rec loss: 0.129, kl: 58.240\n",
            "Epoch 1795\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.034, rec loss: 0.034, kl: 58.187\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 58.219\n",
            "Epoch 1796\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.032, rec loss: 0.032, kl: 58.165\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 58.235\n",
            "Epoch 1797\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 58.203\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 58.271\n",
            "Epoch 1798\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.235\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 58.296\n",
            "Epoch 1799\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.240\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 58.314\n",
            "Epoch 1800\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.257\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 58.366\n",
            "Epoch 1801\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 58.298\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 58.385\n",
            "Epoch 1802\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.346, rec loss: 1.346, kl: 58.716\n",
            "\t[validation] loss: 0.372, rec loss: 0.372, kl: 58.902\n",
            "Epoch 1803\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.100, rec loss: 0.100, kl: 58.774\n",
            "\t[validation] loss: 0.182, rec loss: 0.182, kl: 58.779\n",
            "Epoch 1804\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.052, rec loss: 0.052, kl: 58.627\n",
            "\t[validation] loss: 0.148, rec loss: 0.148, kl: 58.686\n",
            "Epoch 1805\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.041, rec loss: 0.041, kl: 58.594\n",
            "\t[validation] loss: 0.126, rec loss: 0.126, kl: 58.636\n",
            "Epoch 1806\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.035, rec loss: 0.035, kl: 58.582\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 58.667\n",
            "Epoch 1807\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 58.599\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 58.644\n",
            "Epoch 1808\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 58.612\n",
            "\t[validation] loss: 0.123, rec loss: 0.123, kl: 58.631\n",
            "Epoch 1809\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.113, rec loss: 0.113, kl: 58.737\n",
            "\t[validation] loss: 0.146, rec loss: 0.146, kl: 59.029\n",
            "Epoch 1810\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.032, rec loss: 0.032, kl: 58.879\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 58.974\n",
            "Epoch 1811\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 58.904\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 58.983\n",
            "Epoch 1812\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.923\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 59.035\n",
            "Epoch 1813\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 58.907\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 59.044\n",
            "Epoch 1814\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 58.916\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 58.989\n",
            "Epoch 1815\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.032, rec loss: 0.032, kl: 58.928\n",
            "\t[validation] loss: 0.178, rec loss: 0.178, kl: 58.970\n",
            "Epoch 1816\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.402, rec loss: 1.402, kl: 59.037\n",
            "\t[validation] loss: 1.266, rec loss: 1.266, kl: 59.078\n",
            "Epoch 1817\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.305, rec loss: 0.305, kl: 58.798\n",
            "\t[validation] loss: 0.183, rec loss: 0.183, kl: 58.797\n",
            "Epoch 1818\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.057, rec loss: 0.057, kl: 58.697\n",
            "\t[validation] loss: 0.147, rec loss: 0.147, kl: 58.741\n",
            "Epoch 1819\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.042, rec loss: 0.042, kl: 58.633\n",
            "\t[validation] loss: 0.127, rec loss: 0.127, kl: 58.708\n",
            "Epoch 1820\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.036, rec loss: 0.036, kl: 58.621\n",
            "\t[validation] loss: 0.125, rec loss: 0.125, kl: 58.704\n",
            "Epoch 1821\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 58.608\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 58.729\n",
            "Epoch 1822\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 58.627\n",
            "\t[validation] loss: 0.122, rec loss: 0.122, kl: 58.760\n",
            "Epoch 1823\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 58.658\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 58.726\n",
            "Epoch 1824\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 58.682\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 58.788\n",
            "Epoch 1825\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.698\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 58.782\n",
            "Epoch 1826\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 58.725\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 58.736\n",
            "Epoch 1827\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.032, rec loss: 0.032, kl: 58.749\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 58.796\n",
            "Epoch 1828\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.334, rec loss: 1.334, kl: 58.995\n",
            "\t[validation] loss: 0.429, rec loss: 0.429, kl: 59.266\n",
            "Epoch 1829\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.111, rec loss: 0.111, kl: 58.980\n",
            "\t[validation] loss: 0.162, rec loss: 0.162, kl: 58.975\n",
            "Epoch 1830\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.052, rec loss: 0.052, kl: 58.885\n",
            "\t[validation] loss: 0.141, rec loss: 0.141, kl: 58.952\n",
            "Epoch 1831\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.040, rec loss: 0.040, kl: 58.867\n",
            "\t[validation] loss: 0.125, rec loss: 0.125, kl: 58.943\n",
            "Epoch 1832\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.035, rec loss: 0.035, kl: 58.853\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 58.881\n",
            "Epoch 1833\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 58.863\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 58.955\n",
            "Epoch 1834\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 58.843\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 58.883\n",
            "Epoch 1835\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 58.855\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 58.908\n",
            "Epoch 1836\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.882\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 58.943\n",
            "Epoch 1837\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.896\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 58.996\n",
            "Epoch 1838\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 58.932\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 58.958\n",
            "Epoch 1839\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 58.917\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 59.026\n",
            "Epoch 1840\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.038, rec loss: 0.038, kl: 58.925\n",
            "\t[validation] loss: 0.203, rec loss: 0.203, kl: 59.116\n",
            "Epoch 1841\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.522, rec loss: 1.522, kl: 59.209\n",
            "\t[validation] loss: 0.618, rec loss: 0.618, kl: 59.356\n",
            "Epoch 1842\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.171, rec loss: 0.171, kl: 59.008\n",
            "\t[validation] loss: 0.175, rec loss: 0.175, kl: 58.994\n",
            "Epoch 1843\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.056, rec loss: 0.056, kl: 58.873\n",
            "\t[validation] loss: 0.154, rec loss: 0.154, kl: 58.949\n",
            "Epoch 1844\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.044, rec loss: 0.044, kl: 58.836\n",
            "\t[validation] loss: 0.134, rec loss: 0.134, kl: 58.966\n",
            "Epoch 1845\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.038, rec loss: 0.038, kl: 58.868\n",
            "\t[validation] loss: 0.164, rec loss: 0.164, kl: 58.946\n",
            "Epoch 1846\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.036, rec loss: 0.036, kl: 58.895\n",
            "\t[validation] loss: 0.129, rec loss: 0.129, kl: 58.988\n",
            "Epoch 1847\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 58.895\n",
            "\t[validation] loss: 0.119, rec loss: 0.119, kl: 58.988\n",
            "Epoch 1848\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 58.911\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 59.021\n",
            "Epoch 1849\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.896\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 59.044\n",
            "Epoch 1850\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.925, rec loss: 0.925, kl: 58.903\n",
            "\t[validation] loss: 1.774, rec loss: 1.774, kl: 59.257\n",
            "Epoch 1851\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.393, rec loss: 0.393, kl: 58.545\n",
            "\t[validation] loss: 0.182, rec loss: 0.182, kl: 58.520\n",
            "Epoch 1852\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.053, rec loss: 0.053, kl: 58.344\n",
            "\t[validation] loss: 0.142, rec loss: 0.142, kl: 58.502\n",
            "Epoch 1853\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.038, rec loss: 0.038, kl: 58.337\n",
            "\t[validation] loss: 0.138, rec loss: 0.138, kl: 58.457\n",
            "Epoch 1854\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.034, rec loss: 0.034, kl: 58.309\n",
            "\t[validation] loss: 0.125, rec loss: 0.125, kl: 58.423\n",
            "Epoch 1855\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 58.263\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 58.434\n",
            "Epoch 1856\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 58.316\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 58.480\n",
            "Epoch 1857\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.351\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 58.533\n",
            "Epoch 1858\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.397\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 58.544\n",
            "Epoch 1859\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 58.440\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 58.568\n",
            "Epoch 1860\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 58.446\n",
            "\t[validation] loss: 0.153, rec loss: 0.153, kl: 58.524\n",
            "Epoch 1861\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.183, rec loss: 1.183, kl: 58.607\n",
            "\t[validation] loss: 0.871, rec loss: 0.871, kl: 58.895\n",
            "Epoch 1862\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.234, rec loss: 0.234, kl: 58.450\n",
            "\t[validation] loss: 0.178, rec loss: 0.178, kl: 58.598\n",
            "Epoch 1863\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.073, rec loss: 0.073, kl: 58.348\n",
            "\t[validation] loss: 0.148, rec loss: 0.148, kl: 58.495\n",
            "Epoch 1864\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.041, rec loss: 0.041, kl: 58.328\n",
            "\t[validation] loss: 0.133, rec loss: 0.133, kl: 58.517\n",
            "Epoch 1865\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.038, rec loss: 0.038, kl: 58.308\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 58.497\n",
            "Epoch 1866\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 58.355\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 58.532\n",
            "Epoch 1867\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 58.381\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 58.578\n",
            "Epoch 1868\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.036, rec loss: 0.036, kl: 58.392\n",
            "\t[validation] loss: 0.670, rec loss: 0.670, kl: 58.593\n",
            "Epoch 1869\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.895, rec loss: 0.895, kl: 58.650\n",
            "\t[validation] loss: 0.193, rec loss: 0.193, kl: 58.712\n",
            "Epoch 1870\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.054, rec loss: 0.054, kl: 58.421\n",
            "\t[validation] loss: 0.137, rec loss: 0.137, kl: 58.647\n",
            "Epoch 1871\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.039, rec loss: 0.039, kl: 58.401\n",
            "\t[validation] loss: 0.126, rec loss: 0.126, kl: 58.629\n",
            "Epoch 1872\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.034, rec loss: 0.034, kl: 58.390\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 58.592\n",
            "Epoch 1873\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 58.412\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 58.639\n",
            "Epoch 1874\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 58.439\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 58.638\n",
            "Epoch 1875\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 58.438\n",
            "\t[validation] loss: 0.101, rec loss: 0.101, kl: 58.652\n",
            "Epoch 1876\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.438\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 58.596\n",
            "Epoch 1877\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.419\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 58.617\n",
            "Epoch 1878\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 58.460\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 58.574\n",
            "Epoch 1879\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 58.497\n",
            "\t[validation] loss: 0.095, rec loss: 0.095, kl: 58.692\n",
            "Epoch 1880\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 58.519\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 58.729\n",
            "Epoch 1881\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 58.616\n",
            "\t[validation] loss: 0.616, rec loss: 0.616, kl: 58.846\n",
            "Epoch 1882\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 2.129, rec loss: 2.129, kl: 58.922\n",
            "\t[validation] loss: 0.273, rec loss: 0.273, kl: 58.699\n",
            "Epoch 1883\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.091, rec loss: 0.091, kl: 58.479\n",
            "\t[validation] loss: 0.181, rec loss: 0.181, kl: 58.615\n",
            "Epoch 1884\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.053, rec loss: 0.053, kl: 58.364\n",
            "\t[validation] loss: 0.145, rec loss: 0.145, kl: 58.515\n",
            "Epoch 1885\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.043, rec loss: 0.043, kl: 58.357\n",
            "\t[validation] loss: 0.130, rec loss: 0.130, kl: 58.576\n",
            "Epoch 1886\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.040, rec loss: 0.040, kl: 58.408\n",
            "\t[validation] loss: 0.131, rec loss: 0.131, kl: 58.583\n",
            "Epoch 1887\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 58.387\n",
            "\t[validation] loss: 0.119, rec loss: 0.119, kl: 58.572\n",
            "Epoch 1888\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 58.395\n",
            "\t[validation] loss: 0.125, rec loss: 0.125, kl: 58.594\n",
            "Epoch 1889\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 58.424\n",
            "\t[validation] loss: 0.136, rec loss: 0.136, kl: 58.594\n",
            "Epoch 1890\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 58.429\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 58.600\n",
            "Epoch 1891\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 58.448\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 58.610\n",
            "Epoch 1892\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 58.442\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 58.666\n",
            "Epoch 1893\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.484\n",
            "\t[validation] loss: 0.123, rec loss: 0.123, kl: 58.659\n",
            "Epoch 1894\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.567, rec loss: 1.567, kl: 58.684\n",
            "\t[validation] loss: 0.766, rec loss: 0.766, kl: 58.872\n",
            "Epoch 1895\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.296, rec loss: 0.296, kl: 58.587\n",
            "\t[validation] loss: 0.182, rec loss: 0.182, kl: 58.667\n",
            "Epoch 1896\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.060, rec loss: 0.060, kl: 58.491\n",
            "\t[validation] loss: 0.147, rec loss: 0.147, kl: 58.586\n",
            "Epoch 1897\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.045, rec loss: 0.045, kl: 58.450\n",
            "\t[validation] loss: 0.133, rec loss: 0.133, kl: 58.616\n",
            "Epoch 1898\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.036, rec loss: 0.036, kl: 58.472\n",
            "\t[validation] loss: 0.131, rec loss: 0.131, kl: 58.607\n",
            "Epoch 1899\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 58.449\n",
            "\t[validation] loss: 0.119, rec loss: 0.119, kl: 58.577\n",
            "Epoch 1900\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 58.426\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 58.559\n",
            "Epoch 1901\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 58.466\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 58.625\n",
            "Epoch 1902\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 58.462\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 58.616\n",
            "Epoch 1903\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.486, rec loss: 0.486, kl: 58.527\n",
            "\t[validation] loss: 0.332, rec loss: 0.332, kl: 58.566\n",
            "Epoch 1904\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.056, rec loss: 0.056, kl: 58.463\n",
            "\t[validation] loss: 0.132, rec loss: 0.132, kl: 58.552\n",
            "Epoch 1905\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.035, rec loss: 0.035, kl: 58.398\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 58.520\n",
            "Epoch 1906\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 58.402\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 58.488\n",
            "Epoch 1907\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 58.437\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 58.605\n",
            "Epoch 1908\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 58.470\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 58.579\n",
            "Epoch 1909\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 58.499\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 58.679\n",
            "Epoch 1910\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 58.534\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 58.676\n",
            "Epoch 1911\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 58.553\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 58.698\n",
            "Epoch 1912\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.332, rec loss: 1.332, kl: 58.601\n",
            "\t[validation] loss: 0.778, rec loss: 0.778, kl: 58.869\n",
            "Epoch 1913\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.154, rec loss: 0.154, kl: 58.378\n",
            "\t[validation] loss: 0.171, rec loss: 0.171, kl: 58.456\n",
            "Epoch 1914\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.049, rec loss: 0.049, kl: 58.325\n",
            "\t[validation] loss: 0.149, rec loss: 0.149, kl: 58.500\n",
            "Epoch 1915\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.038, rec loss: 0.038, kl: 58.345\n",
            "\t[validation] loss: 0.128, rec loss: 0.128, kl: 58.454\n",
            "Epoch 1916\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.035, rec loss: 0.035, kl: 58.313\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 58.503\n",
            "Epoch 1917\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 58.370\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 58.550\n",
            "Epoch 1918\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 58.431\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 58.568\n",
            "Epoch 1919\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.464\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 58.626\n",
            "Epoch 1920\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.735, rec loss: 0.735, kl: 58.503\n",
            "\t[validation] loss: 1.045, rec loss: 1.045, kl: 58.584\n",
            "Epoch 1921\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.168, rec loss: 0.168, kl: 58.294\n",
            "\t[validation] loss: 0.149, rec loss: 0.149, kl: 58.375\n",
            "Epoch 1922\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.043, rec loss: 0.043, kl: 58.220\n",
            "\t[validation] loss: 0.134, rec loss: 0.134, kl: 58.347\n",
            "Epoch 1923\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.032, rec loss: 0.032, kl: 58.218\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 58.365\n",
            "Epoch 1924\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 58.203\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 58.319\n",
            "Epoch 1925\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 58.249\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 58.453\n",
            "Epoch 1926\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.289\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 58.419\n",
            "Epoch 1927\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 58.327\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 58.447\n",
            "Epoch 1928\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 58.358\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 58.554\n",
            "Epoch 1929\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 58.339\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 58.465\n",
            "Epoch 1930\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.397\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 58.542\n",
            "Epoch 1931\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 58.453\n",
            "\t[validation] loss: 0.207, rec loss: 0.207, kl: 58.661\n",
            "Epoch 1932\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.788, rec loss: 1.788, kl: 59.047\n",
            "\t[validation] loss: 0.346, rec loss: 0.346, kl: 59.099\n",
            "Epoch 1933\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.125, rec loss: 0.125, kl: 58.992\n",
            "\t[validation] loss: 0.172, rec loss: 0.172, kl: 58.992\n",
            "Epoch 1934\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.051, rec loss: 0.051, kl: 58.870\n",
            "\t[validation] loss: 0.144, rec loss: 0.144, kl: 58.918\n",
            "Epoch 1935\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.039, rec loss: 0.039, kl: 58.825\n",
            "\t[validation] loss: 0.134, rec loss: 0.134, kl: 58.885\n",
            "Epoch 1936\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.036, rec loss: 0.036, kl: 58.770\n",
            "\t[validation] loss: 0.123, rec loss: 0.123, kl: 58.806\n",
            "Epoch 1937\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 58.756\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 58.844\n",
            "Epoch 1938\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 58.729\n",
            "\t[validation] loss: 0.119, rec loss: 0.119, kl: 58.779\n",
            "Epoch 1939\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.689\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 58.750\n",
            "Epoch 1940\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 58.733\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 58.819\n",
            "Epoch 1941\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 58.732\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 58.856\n",
            "Epoch 1942\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 58.752\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 58.863\n",
            "Epoch 1943\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 58.775\n",
            "\t[validation] loss: 0.101, rec loss: 0.101, kl: 58.872\n",
            "Epoch 1944\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 58.775\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 58.845\n",
            "Epoch 1945\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 58.817\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 58.909\n",
            "Epoch 1946\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.568, rec loss: 1.568, kl: 58.923\n",
            "\t[validation] loss: 0.743, rec loss: 0.743, kl: 58.991\n",
            "Epoch 1947\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.148, rec loss: 0.148, kl: 58.808\n",
            "\t[validation] loss: 0.206, rec loss: 0.206, kl: 58.851\n",
            "Epoch 1948\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.056, rec loss: 0.056, kl: 58.697\n",
            "\t[validation] loss: 0.151, rec loss: 0.151, kl: 58.797\n",
            "Epoch 1949\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.043, rec loss: 0.043, kl: 58.696\n",
            "\t[validation] loss: 0.145, rec loss: 0.145, kl: 58.785\n",
            "Epoch 1950\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.035, rec loss: 0.035, kl: 58.693\n",
            "\t[validation] loss: 0.125, rec loss: 0.125, kl: 58.805\n",
            "Epoch 1951\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 58.710\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 58.812\n",
            "Epoch 1952\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 58.740\n",
            "\t[validation] loss: 0.123, rec loss: 0.123, kl: 58.870\n",
            "Epoch 1953\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.769\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 58.884\n",
            "Epoch 1954\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.785\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 58.917\n",
            "Epoch 1955\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 58.825\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 58.917\n",
            "Epoch 1956\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 58.806\n",
            "\t[validation] loss: 0.136, rec loss: 0.136, kl: 58.861\n",
            "Epoch 1957\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.833\n",
            "\t[validation] loss: 0.123, rec loss: 0.123, kl: 58.946\n",
            "Epoch 1958\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.838\n",
            "\t[validation] loss: 0.145, rec loss: 0.145, kl: 58.909\n",
            "Epoch 1959\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 58.894\n",
            "\t[validation] loss: 0.156, rec loss: 0.156, kl: 59.036\n",
            "Epoch 1960\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.698, rec loss: 1.698, kl: 59.049\n",
            "\t[validation] loss: 0.275, rec loss: 0.275, kl: 58.916\n",
            "Epoch 1961\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.087, rec loss: 0.087, kl: 58.743\n",
            "\t[validation] loss: 0.158, rec loss: 0.158, kl: 58.782\n",
            "Epoch 1962\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.048, rec loss: 0.048, kl: 58.676\n",
            "\t[validation] loss: 0.132, rec loss: 0.132, kl: 58.779\n",
            "Epoch 1963\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.037, rec loss: 0.037, kl: 58.622\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 58.714\n",
            "Epoch 1964\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 58.587\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 58.664\n",
            "Epoch 1965\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.036, rec loss: 0.036, kl: 58.546\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 58.644\n",
            "Epoch 1966\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 58.562\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 58.694\n",
            "Epoch 1967\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 58.614\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 58.722\n",
            "Epoch 1968\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 58.672\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 58.742\n",
            "Epoch 1969\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.649\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 58.713\n",
            "Epoch 1970\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 58.611\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 58.714\n",
            "Epoch 1971\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 58.641\n",
            "\t[validation] loss: 0.130, rec loss: 0.130, kl: 58.668\n",
            "Epoch 1972\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 58.678\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 58.778\n",
            "Epoch 1973\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.560, rec loss: 1.560, kl: 58.824\n",
            "\t[validation] loss: 0.648, rec loss: 0.648, kl: 58.798\n",
            "Epoch 1974\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.103, rec loss: 0.103, kl: 58.572\n",
            "\t[validation] loss: 0.173, rec loss: 0.173, kl: 58.633\n",
            "Epoch 1975\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.047, rec loss: 0.047, kl: 58.587\n",
            "\t[validation] loss: 0.133, rec loss: 0.133, kl: 58.627\n",
            "Epoch 1976\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.036, rec loss: 0.036, kl: 58.599\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 58.611\n",
            "Epoch 1977\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 58.562\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 58.605\n",
            "Epoch 1978\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 58.596\n",
            "\t[validation] loss: 0.119, rec loss: 0.119, kl: 58.693\n",
            "Epoch 1979\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.594\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 58.587\n",
            "Epoch 1980\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.573\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 58.657\n",
            "Epoch 1981\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 58.590\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 58.635\n",
            "Epoch 1982\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 58.625\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 58.715\n",
            "Epoch 1983\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 58.682\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 58.720\n",
            "Epoch 1984\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 58.733\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 58.815\n",
            "Epoch 1985\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.298, rec loss: 1.298, kl: 58.824\n",
            "\t[validation] loss: 1.019, rec loss: 1.019, kl: 58.906\n",
            "Epoch 1986\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.192, rec loss: 0.192, kl: 58.634\n",
            "\t[validation] loss: 0.210, rec loss: 0.210, kl: 58.677\n",
            "Epoch 1987\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.057, rec loss: 0.057, kl: 58.569\n",
            "\t[validation] loss: 0.138, rec loss: 0.138, kl: 58.724\n",
            "Epoch 1988\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.038, rec loss: 0.038, kl: 58.547\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 58.715\n",
            "Epoch 1989\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 58.534\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 58.677\n",
            "Epoch 1990\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 58.530\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 58.645\n",
            "Epoch 1991\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 58.527\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 58.610\n",
            "Epoch 1992\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.494\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 58.632\n",
            "Epoch 1993\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 58.533\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 58.706\n",
            "Epoch 1994\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.587\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 58.773\n",
            "Epoch 1995\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 58.636\n",
            "\t[validation] loss: 0.101, rec loss: 0.101, kl: 58.813\n",
            "Epoch 1996\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 58.659\n",
            "\t[validation] loss: 0.100, rec loss: 0.100, kl: 58.802\n",
            "Epoch 1997\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 58.686\n",
            "\t[validation] loss: 0.191, rec loss: 0.191, kl: 58.883\n",
            "Epoch 1998\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 58.758\n",
            "\t[validation] loss: 0.119, rec loss: 0.119, kl: 58.897\n",
            "Epoch 1999\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.404, rec loss: 0.404, kl: 58.729\n",
            "\t[validation] loss: 3.936, rec loss: 3.936, kl: 58.827\n",
            "Epoch 2000\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.794, rec loss: 1.794, kl: 58.808\n",
            "\t[validation] loss: 0.255, rec loss: 0.255, kl: 58.770\n",
            "Epoch 2001\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.075, rec loss: 0.075, kl: 58.632\n",
            "\t[validation] loss: 0.159, rec loss: 0.159, kl: 58.705\n",
            "Epoch 2002\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.047, rec loss: 0.047, kl: 58.605\n",
            "\t[validation] loss: 0.139, rec loss: 0.139, kl: 58.669\n",
            "Epoch 2003\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.040, rec loss: 0.040, kl: 58.595\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 58.721\n",
            "Epoch 2004\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 58.618\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 58.714\n",
            "Epoch 2005\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 58.601\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 58.732\n",
            "Epoch 2006\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 58.616\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 58.756\n",
            "Epoch 2007\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.619\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 58.761\n",
            "Epoch 2008\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 58.659\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 58.783\n",
            "Epoch 2009\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 58.682\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 58.810\n",
            "Epoch 2010\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 58.713\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 58.831\n",
            "Epoch 2011\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 58.759\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 58.857\n",
            "Epoch 2012\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 58.791\n",
            "\t[validation] loss: 0.099, rec loss: 0.099, kl: 58.937\n",
            "Epoch 2013\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 58.796\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 58.860\n",
            "Epoch 2014\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 58.807\n",
            "\t[validation] loss: 0.268, rec loss: 0.268, kl: 58.788\n",
            "Epoch 2015\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.396, rec loss: 1.396, kl: 59.015\n",
            "\t[validation] loss: 0.355, rec loss: 0.355, kl: 58.822\n",
            "Epoch 2016\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.229, rec loss: 0.229, kl: 58.737\n",
            "\t[validation] loss: 0.172, rec loss: 0.172, kl: 58.703\n",
            "Epoch 2017\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.046, rec loss: 0.046, kl: 58.593\n",
            "\t[validation] loss: 0.142, rec loss: 0.142, kl: 58.651\n",
            "Epoch 2018\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.037, rec loss: 0.037, kl: 58.567\n",
            "\t[validation] loss: 0.127, rec loss: 0.127, kl: 58.622\n",
            "Epoch 2019\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 58.566\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 58.656\n",
            "Epoch 2020\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 58.562\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 58.654\n",
            "Epoch 2021\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 58.562\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 58.636\n",
            "Epoch 2022\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 58.577\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 58.657\n",
            "Epoch 2023\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 58.619\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 58.683\n",
            "Epoch 2024\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 58.673\n",
            "\t[validation] loss: 0.123, rec loss: 0.123, kl: 58.810\n",
            "Epoch 2025\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.960, rec loss: 0.960, kl: 58.851\n",
            "\t[validation] loss: 1.681, rec loss: 1.681, kl: 58.972\n",
            "Epoch 2026\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.455, rec loss: 0.455, kl: 58.658\n",
            "\t[validation] loss: 0.317, rec loss: 0.317, kl: 58.502\n",
            "Epoch 2027\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.090, rec loss: 0.090, kl: 58.385\n",
            "\t[validation] loss: 0.149, rec loss: 0.149, kl: 58.420\n",
            "Epoch 2028\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.038, rec loss: 0.038, kl: 58.353\n",
            "\t[validation] loss: 0.128, rec loss: 0.128, kl: 58.434\n",
            "Epoch 2029\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.034, rec loss: 0.034, kl: 58.394\n",
            "\t[validation] loss: 0.125, rec loss: 0.125, kl: 58.447\n",
            "Epoch 2030\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 58.379\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 58.450\n",
            "Epoch 2031\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 58.407\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 58.465\n",
            "Epoch 2032\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 58.414\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 58.487\n",
            "Epoch 2033\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 58.428\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 58.494\n",
            "Epoch 2034\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 58.467\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 58.571\n",
            "Epoch 2035\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 58.517\n",
            "\t[validation] loss: 0.100, rec loss: 0.100, kl: 58.580\n",
            "Epoch 2036\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 58.549\n",
            "\t[validation] loss: 0.100, rec loss: 0.100, kl: 58.643\n",
            "Epoch 2037\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 58.585\n",
            "\t[validation] loss: 0.099, rec loss: 0.099, kl: 58.612\n",
            "Epoch 2038\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 58.570\n",
            "\t[validation] loss: 0.099, rec loss: 0.099, kl: 58.652\n",
            "Epoch 2039\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.894, rec loss: 0.894, kl: 58.692\n",
            "\t[validation] loss: 2.737, rec loss: 2.737, kl: 59.393\n",
            "Epoch 2040\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.078, rec loss: 1.078, kl: 59.090\n",
            "\t[validation] loss: 1.383, rec loss: 1.383, kl: 59.177\n",
            "Epoch 2041\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.203, rec loss: 0.203, kl: 58.929\n",
            "\t[validation] loss: 0.167, rec loss: 0.167, kl: 58.906\n",
            "Epoch 2042\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.049, rec loss: 0.049, kl: 58.896\n",
            "\t[validation] loss: 0.136, rec loss: 0.136, kl: 58.906\n",
            "Epoch 2043\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.039, rec loss: 0.039, kl: 58.846\n",
            "\t[validation] loss: 0.127, rec loss: 0.127, kl: 58.827\n",
            "Epoch 2044\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 58.801\n",
            "\t[validation] loss: 0.119, rec loss: 0.119, kl: 58.907\n",
            "Epoch 2045\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 58.845\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 58.886\n",
            "Epoch 2046\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 58.826\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 58.858\n",
            "Epoch 2047\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 58.839\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 58.854\n",
            "Epoch 2048\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 58.815\n",
            "\t[validation] loss: 0.125, rec loss: 0.125, kl: 58.848\n",
            "Epoch 2049\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 58.835\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 58.873\n",
            "Epoch 2050\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 58.865\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 58.923\n",
            "Epoch 2051\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 58.905\n",
            "\t[validation] loss: 0.101, rec loss: 0.101, kl: 58.999\n",
            "Epoch 2052\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.040, rec loss: 1.040, kl: 59.308\n",
            "\t[validation] loss: 2.805, rec loss: 2.805, kl: 59.513\n",
            "Epoch 2053\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.335, rec loss: 0.335, kl: 59.186\n",
            "\t[validation] loss: 0.170, rec loss: 0.170, kl: 59.179\n",
            "Epoch 2054\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.054, rec loss: 0.054, kl: 59.070\n",
            "\t[validation] loss: 0.131, rec loss: 0.131, kl: 59.101\n",
            "Epoch 2055\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.036, rec loss: 0.036, kl: 59.070\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 59.117\n",
            "Epoch 2056\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 59.075\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 59.235\n",
            "Epoch 2057\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 59.147\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 59.239\n",
            "Epoch 2058\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 59.155\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 59.211\n",
            "Epoch 2059\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.158\n",
            "\t[validation] loss: 0.101, rec loss: 0.101, kl: 59.219\n",
            "Epoch 2060\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 59.220\n",
            "\t[validation] loss: 0.152, rec loss: 0.152, kl: 59.310\n",
            "Epoch 2061\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 59.252\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 59.307\n",
            "Epoch 2062\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.239\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 59.316\n",
            "Epoch 2063\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.266\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 59.323\n",
            "Epoch 2064\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 59.271\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 59.336\n",
            "Epoch 2065\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.276\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 59.355\n",
            "Epoch 2066\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 59.297\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 59.363\n",
            "Epoch 2067\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.750, rec loss: 1.750, kl: 59.146\n",
            "\t[validation] loss: 0.276, rec loss: 0.276, kl: 58.972\n",
            "Epoch 2068\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.076, rec loss: 0.076, kl: 58.835\n",
            "\t[validation] loss: 0.169, rec loss: 0.169, kl: 58.836\n",
            "Epoch 2069\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.046, rec loss: 0.046, kl: 58.770\n",
            "\t[validation] loss: 0.138, rec loss: 0.138, kl: 58.826\n",
            "Epoch 2070\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.036, rec loss: 0.036, kl: 58.757\n",
            "\t[validation] loss: 0.125, rec loss: 0.125, kl: 58.870\n",
            "Epoch 2071\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 58.767\n",
            "\t[validation] loss: 0.123, rec loss: 0.123, kl: 58.872\n",
            "Epoch 2072\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.782\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 58.854\n",
            "Epoch 2073\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 58.782\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 58.849\n",
            "Epoch 2074\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 58.772\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 58.871\n",
            "Epoch 2075\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 58.830\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 58.915\n",
            "Epoch 2076\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 58.852\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 58.962\n",
            "Epoch 2077\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 58.880\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 58.982\n",
            "Epoch 2078\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 58.927\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 59.049\n",
            "Epoch 2079\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 58.972\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 59.044\n",
            "Epoch 2080\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.945\n",
            "\t[validation] loss: 0.149, rec loss: 0.149, kl: 59.068\n",
            "Epoch 2081\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.528, rec loss: 1.528, kl: 59.218\n",
            "\t[validation] loss: 0.977, rec loss: 0.977, kl: 58.927\n",
            "Epoch 2082\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.288, rec loss: 0.288, kl: 58.867\n",
            "\t[validation] loss: 0.180, rec loss: 0.180, kl: 58.852\n",
            "Epoch 2083\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.051, rec loss: 0.051, kl: 58.803\n",
            "\t[validation] loss: 0.141, rec loss: 0.141, kl: 58.921\n",
            "Epoch 2084\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.035, rec loss: 0.035, kl: 58.795\n",
            "\t[validation] loss: 0.126, rec loss: 0.126, kl: 58.902\n",
            "Epoch 2085\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.032, rec loss: 0.032, kl: 58.804\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 58.958\n",
            "Epoch 2086\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 58.833\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 58.986\n",
            "Epoch 2087\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 58.869\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 58.993\n",
            "Epoch 2088\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 58.897\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 59.011\n",
            "Epoch 2089\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 58.909\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 59.028\n",
            "Epoch 2090\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 58.965\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 59.084\n",
            "Epoch 2091\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.007\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 59.154\n",
            "Epoch 2092\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.048\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 59.233\n",
            "Epoch 2093\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 59.046\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 59.174\n",
            "Epoch 2094\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.019\n",
            "\t[validation] loss: 0.152, rec loss: 0.152, kl: 59.085\n",
            "Epoch 2095\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.465, rec loss: 1.465, kl: 59.458\n",
            "\t[validation] loss: 0.439, rec loss: 0.439, kl: 59.246\n",
            "Epoch 2096\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.120, rec loss: 0.120, kl: 59.073\n",
            "\t[validation] loss: 0.160, rec loss: 0.160, kl: 59.193\n",
            "Epoch 2097\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.048, rec loss: 0.048, kl: 59.067\n",
            "\t[validation] loss: 0.137, rec loss: 0.137, kl: 59.213\n",
            "Epoch 2098\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.036, rec loss: 0.036, kl: 59.053\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 59.186\n",
            "Epoch 2099\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 59.015\n",
            "\t[validation] loss: 0.119, rec loss: 0.119, kl: 59.170\n",
            "Epoch 2100\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 58.987\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 59.112\n",
            "Epoch 2101\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 59.018\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 59.228\n",
            "Epoch 2102\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 59.047\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 59.230\n",
            "Epoch 2103\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.099\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 59.278\n",
            "Epoch 2104\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 59.110\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 59.294\n",
            "Epoch 2105\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 59.097\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 59.283\n",
            "Epoch 2106\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 59.103\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 59.218\n",
            "Epoch 2107\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.129\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 59.287\n",
            "Epoch 2108\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.301, rec loss: 1.301, kl: 59.469\n",
            "\t[validation] loss: 0.245, rec loss: 0.245, kl: 59.890\n",
            "Epoch 2109\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.073, rec loss: 0.073, kl: 59.536\n",
            "\t[validation] loss: 0.161, rec loss: 0.161, kl: 59.620\n",
            "Epoch 2110\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.040, rec loss: 0.040, kl: 59.394\n",
            "\t[validation] loss: 0.134, rec loss: 0.134, kl: 59.563\n",
            "Epoch 2111\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.032, rec loss: 0.032, kl: 59.389\n",
            "\t[validation] loss: 0.125, rec loss: 0.125, kl: 59.570\n",
            "Epoch 2112\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.211, rec loss: 0.211, kl: 59.445\n",
            "\t[validation] loss: 0.449, rec loss: 0.449, kl: 59.702\n",
            "Epoch 2113\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.411, rec loss: 0.411, kl: 59.336\n",
            "\t[validation] loss: 0.169, rec loss: 0.169, kl: 59.281\n",
            "Epoch 2114\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.041, rec loss: 0.041, kl: 59.093\n",
            "\t[validation] loss: 0.129, rec loss: 0.129, kl: 59.223\n",
            "Epoch 2115\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 59.076\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 59.209\n",
            "Epoch 2116\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 59.025\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 59.199\n",
            "Epoch 2117\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.006\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 59.150\n",
            "Epoch 2118\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 59.022\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 59.190\n",
            "Epoch 2119\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.033\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 59.217\n",
            "Epoch 2120\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.033\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 59.282\n",
            "Epoch 2121\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.043\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 59.205\n",
            "Epoch 2122\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.085\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 59.215\n",
            "Epoch 2123\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.046, rec loss: 0.046, kl: 59.057\n",
            "\t[validation] loss: 0.884, rec loss: 0.884, kl: 59.217\n",
            "Epoch 2124\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.112, rec loss: 1.112, kl: 59.460\n",
            "\t[validation] loss: 0.205, rec loss: 0.205, kl: 59.530\n",
            "Epoch 2125\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.049, rec loss: 0.049, kl: 59.343\n",
            "\t[validation] loss: 0.155, rec loss: 0.155, kl: 59.328\n",
            "Epoch 2126\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.035, rec loss: 0.035, kl: 59.253\n",
            "\t[validation] loss: 0.130, rec loss: 0.130, kl: 59.299\n",
            "Epoch 2127\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 59.202\n",
            "\t[validation] loss: 0.122, rec loss: 0.122, kl: 59.312\n",
            "Epoch 2128\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 59.208\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 59.314\n",
            "Epoch 2129\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 59.211\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 59.292\n",
            "Epoch 2130\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.219\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 59.336\n",
            "Epoch 2131\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.243\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 59.373\n",
            "Epoch 2132\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 59.259\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 59.316\n",
            "Epoch 2133\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.365, rec loss: 1.365, kl: 59.460\n",
            "\t[validation] loss: 1.084, rec loss: 1.084, kl: 59.766\n",
            "Epoch 2134\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.296, rec loss: 0.296, kl: 59.511\n",
            "\t[validation] loss: 0.204, rec loss: 0.204, kl: 59.605\n",
            "Epoch 2135\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.058, rec loss: 0.058, kl: 59.427\n",
            "\t[validation] loss: 0.154, rec loss: 0.154, kl: 59.569\n",
            "Epoch 2136\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.039, rec loss: 0.039, kl: 59.403\n",
            "\t[validation] loss: 0.135, rec loss: 0.135, kl: 59.558\n",
            "Epoch 2137\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 59.393\n",
            "\t[validation] loss: 0.136, rec loss: 0.136, kl: 59.554\n",
            "Epoch 2138\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 59.422\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 59.542\n",
            "Epoch 2139\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 59.409\n",
            "\t[validation] loss: 0.119, rec loss: 0.119, kl: 59.543\n",
            "Epoch 2140\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 59.418\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 59.562\n",
            "Epoch 2141\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 59.427\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 59.568\n",
            "Epoch 2142\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.431\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 59.541\n",
            "Epoch 2143\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 59.415\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 59.545\n",
            "Epoch 2144\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 59.431\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 59.533\n",
            "Epoch 2145\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.443\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 59.596\n",
            "Epoch 2146\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 59.448\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 59.577\n",
            "Epoch 2147\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.471\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 59.629\n",
            "Epoch 2148\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.493\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 59.622\n",
            "Epoch 2149\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.901, rec loss: 1.901, kl: 59.688\n",
            "\t[validation] loss: 0.307, rec loss: 0.307, kl: 59.678\n",
            "Epoch 2150\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.096, rec loss: 0.096, kl: 59.504\n",
            "\t[validation] loss: 0.178, rec loss: 0.178, kl: 59.566\n",
            "Epoch 2151\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.050, rec loss: 0.050, kl: 59.464\n",
            "\t[validation] loss: 0.143, rec loss: 0.143, kl: 59.576\n",
            "Epoch 2152\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.037, rec loss: 0.037, kl: 59.440\n",
            "\t[validation] loss: 0.129, rec loss: 0.129, kl: 59.551\n",
            "Epoch 2153\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 59.428\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 59.583\n",
            "Epoch 2154\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 59.439\n",
            "\t[validation] loss: 0.125, rec loss: 0.125, kl: 59.543\n",
            "Epoch 2155\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 59.413\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 59.543\n",
            "Epoch 2156\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 59.432\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 59.565\n",
            "Epoch 2157\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 59.469\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 59.610\n",
            "Epoch 2158\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 59.500\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 59.649\n",
            "Epoch 2159\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.035, rec loss: 0.035, kl: 59.504\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 59.665\n",
            "Epoch 2160\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.536\n",
            "\t[validation] loss: 0.126, rec loss: 0.126, kl: 59.739\n",
            "Epoch 2161\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.581\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 59.730\n",
            "Epoch 2162\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 59.591\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 59.737\n",
            "Epoch 2163\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.046, rec loss: 0.046, kl: 59.658\n",
            "\t[validation] loss: 0.693, rec loss: 0.693, kl: 59.959\n",
            "Epoch 2164\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.277, rec loss: 1.277, kl: 59.925\n",
            "\t[validation] loss: 0.244, rec loss: 0.244, kl: 60.132\n",
            "Epoch 2165\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.066, rec loss: 0.066, kl: 59.758\n",
            "\t[validation] loss: 0.161, rec loss: 0.161, kl: 59.934\n",
            "Epoch 2166\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.039, rec loss: 0.039, kl: 59.676\n",
            "\t[validation] loss: 0.127, rec loss: 0.127, kl: 59.863\n",
            "Epoch 2167\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.032, rec loss: 0.032, kl: 59.643\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 59.844\n",
            "Epoch 2168\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 59.646\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 59.870\n",
            "Epoch 2169\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 59.652\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 59.848\n",
            "Epoch 2170\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.641\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 59.772\n",
            "Epoch 2171\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 59.648\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 59.864\n",
            "Epoch 2172\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 59.701\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 59.821\n",
            "Epoch 2173\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.684\n",
            "\t[validation] loss: 0.100, rec loss: 0.100, kl: 59.875\n",
            "Epoch 2174\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.341, rec loss: 1.341, kl: 60.020\n",
            "\t[validation] loss: 0.507, rec loss: 0.507, kl: 60.317\n",
            "Epoch 2175\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.141, rec loss: 0.141, kl: 59.942\n",
            "\t[validation] loss: 0.189, rec loss: 0.189, kl: 60.071\n",
            "Epoch 2176\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.118, rec loss: 0.118, kl: 59.643\n",
            "\t[validation] loss: 0.142, rec loss: 0.142, kl: 59.754\n",
            "Epoch 2177\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.034, rec loss: 0.034, kl: 59.569\n",
            "\t[validation] loss: 0.128, rec loss: 0.128, kl: 59.749\n",
            "Epoch 2178\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 59.544\n",
            "\t[validation] loss: 0.123, rec loss: 0.123, kl: 59.757\n",
            "Epoch 2179\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 59.567\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 59.751\n",
            "Epoch 2180\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 59.574\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 59.811\n",
            "Epoch 2181\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.608\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 59.752\n",
            "Epoch 2182\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 59.597\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 59.795\n",
            "Epoch 2183\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 59.572\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 59.747\n",
            "Epoch 2184\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.609\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 59.776\n",
            "Epoch 2185\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.632\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 59.783\n",
            "Epoch 2186\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.668\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 59.799\n",
            "Epoch 2187\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 59.751\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 59.921\n",
            "Epoch 2188\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.717\n",
            "\t[validation] loss: 0.189, rec loss: 0.189, kl: 59.829\n",
            "Epoch 2189\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.788, rec loss: 1.788, kl: 59.950\n",
            "\t[validation] loss: 0.317, rec loss: 0.317, kl: 60.291\n",
            "Epoch 2190\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.089, rec loss: 0.089, kl: 60.035\n",
            "\t[validation] loss: 0.173, rec loss: 0.173, kl: 60.106\n",
            "Epoch 2191\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.047, rec loss: 0.047, kl: 59.970\n",
            "\t[validation] loss: 0.140, rec loss: 0.140, kl: 60.099\n",
            "Epoch 2192\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.036, rec loss: 0.036, kl: 59.943\n",
            "\t[validation] loss: 0.136, rec loss: 0.136, kl: 60.034\n",
            "Epoch 2193\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 59.919\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 60.020\n",
            "Epoch 2194\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 59.901\n",
            "\t[validation] loss: 0.119, rec loss: 0.119, kl: 60.032\n",
            "Epoch 2195\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 59.914\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 60.044\n",
            "Epoch 2196\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 59.914\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 60.062\n",
            "Epoch 2197\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.955\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 60.100\n",
            "Epoch 2198\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.960\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 60.089\n",
            "Epoch 2199\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.930\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 60.059\n",
            "Epoch 2200\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 59.958\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 60.114\n",
            "Epoch 2201\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.975\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 60.102\n",
            "Epoch 2202\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.996\n",
            "\t[validation] loss: 0.119, rec loss: 0.119, kl: 60.135\n",
            "Epoch 2203\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.131, rec loss: 1.131, kl: 59.935\n",
            "\t[validation] loss: 0.202, rec loss: 0.202, kl: 59.817\n",
            "Epoch 2204\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.084, rec loss: 0.084, kl: 59.863\n",
            "\t[validation] loss: 0.151, rec loss: 0.151, kl: 59.788\n",
            "Epoch 2205\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.034, rec loss: 0.034, kl: 59.733\n",
            "\t[validation] loss: 0.127, rec loss: 0.127, kl: 59.770\n",
            "Epoch 2206\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 59.684\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 59.738\n",
            "Epoch 2207\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 59.657\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 59.714\n",
            "Epoch 2208\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 59.643\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 59.747\n",
            "Epoch 2209\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.632\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 59.698\n",
            "Epoch 2210\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.602\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 59.680\n",
            "Epoch 2211\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.591\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 59.660\n",
            "Epoch 2212\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.673\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 59.728\n",
            "Epoch 2213\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 59.634\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 59.638\n",
            "Epoch 2214\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.047, rec loss: 0.047, kl: 59.630\n",
            "\t[validation] loss: 0.392, rec loss: 0.392, kl: 59.615\n",
            "Epoch 2215\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.468, rec loss: 1.468, kl: 60.011\n",
            "\t[validation] loss: 0.391, rec loss: 0.391, kl: 59.959\n",
            "Epoch 2216\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.442, rec loss: 0.442, kl: 59.872\n",
            "\t[validation] loss: 0.194, rec loss: 0.194, kl: 59.918\n",
            "Epoch 2217\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.055, rec loss: 0.055, kl: 59.851\n",
            "\t[validation] loss: 0.152, rec loss: 0.152, kl: 59.889\n",
            "Epoch 2218\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.039, rec loss: 0.039, kl: 59.785\n",
            "\t[validation] loss: 0.137, rec loss: 0.137, kl: 59.852\n",
            "Epoch 2219\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.032, rec loss: 0.032, kl: 59.769\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 59.851\n",
            "Epoch 2220\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 59.758\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 59.844\n",
            "Epoch 2221\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 59.737\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 59.852\n",
            "Epoch 2222\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 59.744\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 59.843\n",
            "Epoch 2223\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.737\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 59.779\n",
            "Epoch 2224\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.709\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 59.785\n",
            "Epoch 2225\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.691\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 59.740\n",
            "Epoch 2226\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.649\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 59.735\n",
            "Epoch 2227\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.684\n",
            "\t[validation] loss: 0.100, rec loss: 0.100, kl: 59.759\n",
            "Epoch 2228\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.712\n",
            "\t[validation] loss: 0.101, rec loss: 0.101, kl: 59.787\n",
            "Epoch 2229\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.634, rec loss: 0.634, kl: 59.741\n",
            "\t[validation] loss: 3.711, rec loss: 3.711, kl: 60.366\n",
            "Epoch 2230\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.888, rec loss: 0.888, kl: 60.331\n",
            "\t[validation] loss: 0.221, rec loss: 0.221, kl: 60.311\n",
            "Epoch 2231\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.058, rec loss: 0.058, kl: 60.119\n",
            "\t[validation] loss: 0.152, rec loss: 0.152, kl: 60.098\n",
            "Epoch 2232\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.039, rec loss: 0.039, kl: 60.017\n",
            "\t[validation] loss: 0.130, rec loss: 0.130, kl: 60.063\n",
            "Epoch 2233\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 59.971\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 59.986\n",
            "Epoch 2234\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 59.961\n",
            "\t[validation] loss: 0.122, rec loss: 0.122, kl: 60.033\n",
            "Epoch 2235\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 59.956\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 60.029\n",
            "Epoch 2236\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.951\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 60.011\n",
            "Epoch 2237\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.967\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 60.015\n",
            "Epoch 2238\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 60.002\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 60.065\n",
            "Epoch 2239\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 59.993\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 60.064\n",
            "Epoch 2240\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 60.051\n",
            "\t[validation] loss: 0.119, rec loss: 0.119, kl: 60.089\n",
            "Epoch 2241\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 59.982\n",
            "\t[validation] loss: 0.139, rec loss: 0.139, kl: 59.970\n",
            "Epoch 2242\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.671, rec loss: 0.671, kl: 60.007\n",
            "\t[validation] loss: 6.717, rec loss: 6.717, kl: 60.372\n",
            "Epoch 2243\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.769, rec loss: 0.769, kl: 60.056\n",
            "\t[validation] loss: 0.187, rec loss: 0.187, kl: 59.897\n",
            "Epoch 2244\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.048, rec loss: 0.048, kl: 59.809\n",
            "\t[validation] loss: 0.144, rec loss: 0.144, kl: 59.795\n",
            "Epoch 2245\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.034, rec loss: 0.034, kl: 59.788\n",
            "\t[validation] loss: 0.126, rec loss: 0.126, kl: 59.811\n",
            "Epoch 2246\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 59.783\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 59.816\n",
            "Epoch 2247\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 59.755\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 59.727\n",
            "Epoch 2248\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.717\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 59.739\n",
            "Epoch 2249\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.693\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 59.751\n",
            "Epoch 2250\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 59.712\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 59.741\n",
            "Epoch 2251\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.721\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 59.727\n",
            "Epoch 2252\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 59.688\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 59.670\n",
            "Epoch 2253\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.660\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 59.748\n",
            "Epoch 2254\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 59.711\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 59.759\n",
            "Epoch 2255\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.644, rec loss: 0.644, kl: 59.795\n",
            "\t[validation] loss: 2.616, rec loss: 2.616, kl: 60.120\n",
            "Epoch 2256\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.542, rec loss: 0.542, kl: 59.808\n",
            "\t[validation] loss: 0.184, rec loss: 0.184, kl: 59.747\n",
            "Epoch 2257\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.045, rec loss: 0.045, kl: 59.711\n",
            "\t[validation] loss: 0.147, rec loss: 0.147, kl: 59.811\n",
            "Epoch 2258\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 59.724\n",
            "\t[validation] loss: 0.126, rec loss: 0.126, kl: 59.762\n",
            "Epoch 2259\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 59.707\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 59.763\n",
            "Epoch 2260\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 59.714\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 59.809\n",
            "Epoch 2261\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 59.700\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 59.750\n",
            "Epoch 2262\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.715\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 59.817\n",
            "Epoch 2263\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.708\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 59.784\n",
            "Epoch 2264\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.714\n",
            "\t[validation] loss: 0.143, rec loss: 0.143, kl: 59.829\n",
            "Epoch 2265\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.337, rec loss: 1.337, kl: 59.766\n",
            "\t[validation] loss: 1.520, rec loss: 1.520, kl: 60.176\n",
            "Epoch 2266\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.289, rec loss: 0.289, kl: 59.632\n",
            "\t[validation] loss: 0.191, rec loss: 0.191, kl: 59.564\n",
            "Epoch 2267\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.059, rec loss: 0.059, kl: 59.395\n",
            "\t[validation] loss: 0.154, rec loss: 0.154, kl: 59.399\n",
            "Epoch 2268\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.036, rec loss: 0.036, kl: 59.384\n",
            "\t[validation] loss: 0.142, rec loss: 0.142, kl: 59.452\n",
            "Epoch 2269\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 59.396\n",
            "\t[validation] loss: 0.132, rec loss: 0.132, kl: 59.465\n",
            "Epoch 2270\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 59.445\n",
            "\t[validation] loss: 0.122, rec loss: 0.122, kl: 59.537\n",
            "Epoch 2271\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 59.461\n",
            "\t[validation] loss: 0.133, rec loss: 0.133, kl: 59.545\n",
            "Epoch 2272\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 59.495\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 59.558\n",
            "Epoch 2273\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.489\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 59.570\n",
            "Epoch 2274\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.481\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 59.557\n",
            "Epoch 2275\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.512\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 59.574\n",
            "Epoch 2276\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.512\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 59.623\n",
            "Epoch 2277\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.102, rec loss: 1.102, kl: 59.841\n",
            "\t[validation] loss: 0.294, rec loss: 0.294, kl: 59.687\n",
            "Epoch 2278\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.072, rec loss: 0.072, kl: 59.605\n",
            "\t[validation] loss: 0.162, rec loss: 0.162, kl: 59.631\n",
            "Epoch 2279\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.035, rec loss: 0.035, kl: 59.527\n",
            "\t[validation] loss: 0.135, rec loss: 0.135, kl: 59.563\n",
            "Epoch 2280\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 59.501\n",
            "\t[validation] loss: 0.125, rec loss: 0.125, kl: 59.564\n",
            "Epoch 2281\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 59.488\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 59.551\n",
            "Epoch 2282\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 59.514\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 59.568\n",
            "Epoch 2283\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 59.520\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 59.592\n",
            "Epoch 2284\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.516\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 59.602\n",
            "Epoch 2285\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 59.552\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 59.582\n",
            "Epoch 2286\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.492\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 59.574\n",
            "Epoch 2287\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 59.531\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 59.625\n",
            "Epoch 2288\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 59.500\n",
            "\t[validation] loss: 0.176, rec loss: 0.176, kl: 59.530\n",
            "Epoch 2289\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 59.545\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 59.604\n",
            "Epoch 2290\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 59.587\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 59.612\n",
            "Epoch 2291\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.643, rec loss: 1.643, kl: 59.827\n",
            "\t[validation] loss: 0.422, rec loss: 0.422, kl: 59.767\n",
            "Epoch 2292\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.114, rec loss: 0.114, kl: 59.745\n",
            "\t[validation] loss: 0.161, rec loss: 0.161, kl: 59.684\n",
            "Epoch 2293\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.043, rec loss: 0.043, kl: 59.610\n",
            "\t[validation] loss: 0.132, rec loss: 0.132, kl: 59.656\n",
            "Epoch 2294\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 59.595\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 59.655\n",
            "Epoch 2295\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 59.598\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 59.634\n",
            "Epoch 2296\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 59.616\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 59.709\n",
            "Epoch 2297\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.623\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 59.687\n",
            "Epoch 2298\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 59.629\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 59.696\n",
            "Epoch 2299\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.640\n",
            "\t[validation] loss: 0.098, rec loss: 0.098, kl: 59.687\n",
            "Epoch 2300\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 59.649\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 59.713\n",
            "Epoch 2301\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.117, rec loss: 1.117, kl: 59.662\n",
            "\t[validation] loss: 0.500, rec loss: 0.500, kl: 59.828\n",
            "Epoch 2302\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.120, rec loss: 0.120, kl: 59.680\n",
            "\t[validation] loss: 0.167, rec loss: 0.167, kl: 59.682\n",
            "Epoch 2303\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.039, rec loss: 0.039, kl: 59.612\n",
            "\t[validation] loss: 0.136, rec loss: 0.136, kl: 59.655\n",
            "Epoch 2304\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 59.604\n",
            "\t[validation] loss: 0.137, rec loss: 0.137, kl: 59.699\n",
            "Epoch 2305\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 59.604\n",
            "\t[validation] loss: 0.122, rec loss: 0.122, kl: 59.648\n",
            "Epoch 2306\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 59.585\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 59.670\n",
            "Epoch 2307\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.587\n",
            "\t[validation] loss: 0.125, rec loss: 0.125, kl: 59.588\n",
            "Epoch 2308\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.608\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 59.658\n",
            "Epoch 2309\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.594\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 59.643\n",
            "Epoch 2310\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.570\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 59.681\n",
            "Epoch 2311\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 59.595\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 59.676\n",
            "Epoch 2312\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 59.611\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 59.657\n",
            "Epoch 2313\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 59.607\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 59.694\n",
            "Epoch 2314\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 59.633\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 59.719\n",
            "Epoch 2315\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.855, rec loss: 0.855, kl: 59.779\n",
            "\t[validation] loss: 4.587, rec loss: 4.587, kl: 60.008\n",
            "Epoch 2316\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.684, rec loss: 0.684, kl: 59.794\n",
            "\t[validation] loss: 0.191, rec loss: 0.191, kl: 59.746\n",
            "Epoch 2317\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.049, rec loss: 0.049, kl: 59.628\n",
            "\t[validation] loss: 0.145, rec loss: 0.145, kl: 59.698\n",
            "Epoch 2318\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.035, rec loss: 0.035, kl: 59.688\n",
            "\t[validation] loss: 0.128, rec loss: 0.128, kl: 59.746\n",
            "Epoch 2319\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 59.663\n",
            "\t[validation] loss: 0.123, rec loss: 0.123, kl: 59.709\n",
            "Epoch 2320\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 59.634\n",
            "\t[validation] loss: 0.126, rec loss: 0.126, kl: 59.725\n",
            "Epoch 2321\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 59.644\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 59.720\n",
            "Epoch 2322\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.664\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 59.707\n",
            "Epoch 2323\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 59.649\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 59.703\n",
            "Epoch 2324\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.684\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 59.775\n",
            "Epoch 2325\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.052, rec loss: 0.052, kl: 59.763\n",
            "\t[validation] loss: 3.932, rec loss: 3.932, kl: 59.823\n",
            "Epoch 2326\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.584, rec loss: 1.584, kl: 59.959\n",
            "\t[validation] loss: 0.227, rec loss: 0.227, kl: 59.956\n",
            "Epoch 2327\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.074, rec loss: 0.074, kl: 59.811\n",
            "\t[validation] loss: 0.168, rec loss: 0.168, kl: 59.892\n",
            "Epoch 2328\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.041, rec loss: 0.041, kl: 59.792\n",
            "\t[validation] loss: 0.139, rec loss: 0.139, kl: 59.829\n",
            "Epoch 2329\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 59.761\n",
            "\t[validation] loss: 0.128, rec loss: 0.128, kl: 59.829\n",
            "Epoch 2330\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 59.749\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 59.827\n",
            "Epoch 2331\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 59.755\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 59.833\n",
            "Epoch 2332\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 59.752\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 59.794\n",
            "Epoch 2333\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.778\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 59.822\n",
            "Epoch 2334\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.776\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 59.807\n",
            "Epoch 2335\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.794\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 59.833\n",
            "Epoch 2336\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.796\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 59.891\n",
            "Epoch 2337\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 59.824\n",
            "\t[validation] loss: 0.125, rec loss: 0.125, kl: 59.893\n",
            "Epoch 2338\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 59.826\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 59.849\n",
            "Epoch 2339\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 59.832\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 59.889\n",
            "Epoch 2340\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 59.889\n",
            "\t[validation] loss: 0.142, rec loss: 0.142, kl: 59.906\n",
            "Epoch 2341\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.866\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 59.867\n",
            "Epoch 2342\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.340, rec loss: 0.340, kl: 59.820\n",
            "\t[validation] loss: 3.093, rec loss: 3.093, kl: 60.216\n",
            "Epoch 2343\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.258, rec loss: 1.258, kl: 59.860\n",
            "\t[validation] loss: 0.222, rec loss: 0.222, kl: 59.556\n",
            "Epoch 2344\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.056, rec loss: 0.056, kl: 59.537\n",
            "\t[validation] loss: 0.166, rec loss: 0.166, kl: 59.623\n",
            "Epoch 2345\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.036, rec loss: 0.036, kl: 59.549\n",
            "\t[validation] loss: 0.133, rec loss: 0.133, kl: 59.546\n",
            "Epoch 2346\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 59.514\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 59.496\n",
            "Epoch 2347\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 59.488\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 59.496\n",
            "Epoch 2348\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.552\n",
            "\t[validation] loss: 0.132, rec loss: 0.132, kl: 59.568\n",
            "Epoch 2349\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 59.570\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 59.558\n",
            "Epoch 2350\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.587\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 59.577\n",
            "Epoch 2351\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.574\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 59.556\n",
            "Epoch 2352\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 59.593\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 59.609\n",
            "Epoch 2353\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 59.595\n",
            "\t[validation] loss: 0.101, rec loss: 0.101, kl: 59.579\n",
            "Epoch 2354\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.789, rec loss: 0.789, kl: 59.743\n",
            "\t[validation] loss: 0.351, rec loss: 0.351, kl: 59.938\n",
            "Epoch 2355\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.089, rec loss: 0.089, kl: 59.964\n",
            "\t[validation] loss: 0.164, rec loss: 0.164, kl: 59.920\n",
            "Epoch 2356\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.035, rec loss: 0.035, kl: 59.875\n",
            "\t[validation] loss: 0.135, rec loss: 0.135, kl: 59.840\n",
            "Epoch 2357\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 59.851\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 59.820\n",
            "Epoch 2358\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.784\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 59.775\n",
            "Epoch 2359\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 59.779\n",
            "\t[validation] loss: 0.131, rec loss: 0.131, kl: 59.774\n",
            "Epoch 2360\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.760\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 59.764\n",
            "Epoch 2361\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 59.782\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 59.830\n",
            "Epoch 2362\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 59.800\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 59.817\n",
            "Epoch 2363\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 59.758\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 59.774\n",
            "Epoch 2364\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.045, rec loss: 1.045, kl: 59.765\n",
            "\t[validation] loss: 2.114, rec loss: 2.114, kl: 60.061\n",
            "Epoch 2365\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.374, rec loss: 0.374, kl: 60.016\n",
            "\t[validation] loss: 0.189, rec loss: 0.189, kl: 60.047\n",
            "Epoch 2366\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.046, rec loss: 0.046, kl: 59.982\n",
            "\t[validation] loss: 0.159, rec loss: 0.159, kl: 60.001\n",
            "Epoch 2367\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.035, rec loss: 0.035, kl: 59.960\n",
            "\t[validation] loss: 0.136, rec loss: 0.136, kl: 59.960\n",
            "Epoch 2368\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 59.911\n",
            "\t[validation] loss: 0.128, rec loss: 0.128, kl: 59.933\n",
            "Epoch 2369\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 59.856\n",
            "\t[validation] loss: 0.131, rec loss: 0.131, kl: 59.865\n",
            "Epoch 2370\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 59.856\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 59.885\n",
            "Epoch 2371\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.861\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 59.875\n",
            "Epoch 2372\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.890\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 59.940\n",
            "Epoch 2373\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.938\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 59.929\n",
            "Epoch 2374\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 59.953\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 60.032\n",
            "Epoch 2375\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 59.968\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 59.988\n",
            "Epoch 2376\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 59.980\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 60.046\n",
            "Epoch 2377\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 59.972\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 60.032\n",
            "Epoch 2378\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.510, rec loss: 0.510, kl: 60.014\n",
            "\t[validation] loss: 3.092, rec loss: 3.092, kl: 60.352\n",
            "Epoch 2379\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.602, rec loss: 0.602, kl: 60.186\n",
            "\t[validation] loss: 0.257, rec loss: 0.257, kl: 60.024\n",
            "Epoch 2380\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.048, rec loss: 0.048, kl: 59.928\n",
            "\t[validation] loss: 0.153, rec loss: 0.153, kl: 59.981\n",
            "Epoch 2381\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 59.901\n",
            "\t[validation] loss: 0.136, rec loss: 0.136, kl: 59.896\n",
            "Epoch 2382\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 59.873\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 59.913\n",
            "Epoch 2383\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 59.883\n",
            "\t[validation] loss: 0.123, rec loss: 0.123, kl: 59.949\n",
            "Epoch 2384\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.870\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 59.906\n",
            "Epoch 2385\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 59.863\n",
            "\t[validation] loss: 0.126, rec loss: 0.126, kl: 59.940\n",
            "Epoch 2386\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.859\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 59.877\n",
            "Epoch 2387\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 59.872\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 59.912\n",
            "Epoch 2388\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 59.880\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 59.939\n",
            "Epoch 2389\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 59.914\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 59.913\n",
            "Epoch 2390\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 59.901\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 59.940\n",
            "Epoch 2391\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.132, rec loss: 0.132, kl: 59.915\n",
            "\t[validation] loss: 2.048, rec loss: 2.048, kl: 59.918\n",
            "Epoch 2392\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.338, rec loss: 1.338, kl: 59.841\n",
            "\t[validation] loss: 0.246, rec loss: 0.246, kl: 59.865\n",
            "Epoch 2393\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.057, rec loss: 0.057, kl: 59.830\n",
            "\t[validation] loss: 0.153, rec loss: 0.153, kl: 59.860\n",
            "Epoch 2394\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.035, rec loss: 0.035, kl: 59.794\n",
            "\t[validation] loss: 0.144, rec loss: 0.144, kl: 59.824\n",
            "Epoch 2395\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 59.796\n",
            "\t[validation] loss: 0.128, rec loss: 0.128, kl: 59.819\n",
            "Epoch 2396\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 59.768\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 59.774\n",
            "Epoch 2397\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.773\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 59.804\n",
            "Epoch 2398\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.739\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 59.794\n",
            "Epoch 2399\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 59.753\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 59.801\n",
            "Epoch 2400\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 59.742\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 59.794\n",
            "Epoch 2401\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 59.781\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 59.831\n",
            "Epoch 2402\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.853, rec loss: 0.853, kl: 59.940\n",
            "\t[validation] loss: 0.289, rec loss: 0.289, kl: 60.075\n",
            "Epoch 2403\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.062, rec loss: 0.062, kl: 59.978\n",
            "\t[validation] loss: 0.155, rec loss: 0.155, kl: 59.960\n",
            "Epoch 2404\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.034, rec loss: 0.034, kl: 59.910\n",
            "\t[validation] loss: 0.137, rec loss: 0.137, kl: 59.969\n",
            "Epoch 2405\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 59.942\n",
            "\t[validation] loss: 0.126, rec loss: 0.126, kl: 59.948\n",
            "Epoch 2406\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 59.935\n",
            "\t[validation] loss: 0.125, rec loss: 0.125, kl: 59.930\n",
            "Epoch 2407\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.895\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 59.912\n",
            "Epoch 2408\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 59.917\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 59.956\n",
            "Epoch 2409\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 59.952\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 59.933\n",
            "Epoch 2410\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 59.924\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 59.939\n",
            "Epoch 2411\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 59.967\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 60.032\n",
            "Epoch 2412\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.070, rec loss: 0.070, kl: 59.978\n",
            "\t[validation] loss: 4.071, rec loss: 4.071, kl: 59.767\n",
            "Epoch 2413\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.229, rec loss: 1.229, kl: 60.096\n",
            "\t[validation] loss: 0.218, rec loss: 0.218, kl: 60.153\n",
            "Epoch 2414\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.052, rec loss: 0.052, kl: 60.119\n",
            "\t[validation] loss: 0.155, rec loss: 0.155, kl: 60.134\n",
            "Epoch 2415\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 60.087\n",
            "\t[validation] loss: 0.134, rec loss: 0.134, kl: 60.125\n",
            "Epoch 2416\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 60.046\n",
            "\t[validation] loss: 0.132, rec loss: 0.132, kl: 60.076\n",
            "Epoch 2417\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 60.025\n",
            "\t[validation] loss: 0.126, rec loss: 0.126, kl: 60.087\n",
            "Epoch 2418\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 60.064\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 60.117\n",
            "Epoch 2419\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.070\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 60.076\n",
            "Epoch 2420\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.057\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 60.072\n",
            "Epoch 2421\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.069\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 60.088\n",
            "Epoch 2422\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.074\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 60.125\n",
            "Epoch 2423\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.109\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 60.110\n",
            "Epoch 2424\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 60.082\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 60.117\n",
            "Epoch 2425\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 60.103\n",
            "\t[validation] loss: 0.138, rec loss: 0.138, kl: 60.157\n",
            "Epoch 2426\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.156\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 60.130\n",
            "Epoch 2427\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.804, rec loss: 0.804, kl: 60.170\n",
            "\t[validation] loss: 3.926, rec loss: 3.926, kl: 60.292\n",
            "Epoch 2428\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.671, rec loss: 0.671, kl: 60.360\n",
            "\t[validation] loss: 0.221, rec loss: 0.221, kl: 60.335\n",
            "Epoch 2429\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.056, rec loss: 0.056, kl: 60.246\n",
            "\t[validation] loss: 0.153, rec loss: 0.153, kl: 60.225\n",
            "Epoch 2430\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 60.120\n",
            "\t[validation] loss: 0.137, rec loss: 0.137, kl: 60.135\n",
            "Epoch 2431\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 60.104\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 60.123\n",
            "Epoch 2432\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 60.091\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 60.106\n",
            "Epoch 2433\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 60.024\n",
            "\t[validation] loss: 0.159, rec loss: 0.159, kl: 59.687\n",
            "Epoch 2434\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.066, rec loss: 0.066, kl: 59.792\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 59.838\n",
            "Epoch 2435\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.867\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 59.857\n",
            "Epoch 2436\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.864\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 59.810\n",
            "Epoch 2437\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.843\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 59.864\n",
            "Epoch 2438\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.842\n",
            "\t[validation] loss: 0.250, rec loss: 0.250, kl: 59.705\n",
            "Epoch 2439\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.460, rec loss: 0.460, kl: 59.943\n",
            "\t[validation] loss: 1.070, rec loss: 1.070, kl: 60.097\n",
            "Epoch 2440\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.535, rec loss: 0.535, kl: 60.110\n",
            "\t[validation] loss: 1.477, rec loss: 1.477, kl: 60.108\n",
            "Epoch 2441\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.220, rec loss: 0.220, kl: 59.898\n",
            "\t[validation] loss: 0.171, rec loss: 0.171, kl: 59.822\n",
            "Epoch 2442\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.036, rec loss: 0.036, kl: 59.850\n",
            "\t[validation] loss: 0.141, rec loss: 0.141, kl: 59.831\n",
            "Epoch 2443\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 59.849\n",
            "\t[validation] loss: 0.129, rec loss: 0.129, kl: 59.844\n",
            "Epoch 2444\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 59.848\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 59.833\n",
            "Epoch 2445\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 59.851\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 59.830\n",
            "Epoch 2446\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.885\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 59.884\n",
            "Epoch 2447\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.910\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 59.878\n",
            "Epoch 2448\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 59.905\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 59.887\n",
            "Epoch 2449\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 59.929\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 59.890\n",
            "Epoch 2450\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.915\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 59.871\n",
            "Epoch 2451\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.910\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 59.948\n",
            "Epoch 2452\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 59.962\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 59.928\n",
            "Epoch 2453\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 59.972\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 59.954\n",
            "Epoch 2454\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 60.007\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 59.962\n",
            "Epoch 2455\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.033\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 60.019\n",
            "Epoch 2456\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.497, rec loss: 1.497, kl: 60.173\n",
            "\t[validation] loss: 0.490, rec loss: 0.490, kl: 60.137\n",
            "Epoch 2457\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.117, rec loss: 0.117, kl: 59.988\n",
            "\t[validation] loss: 0.183, rec loss: 0.183, kl: 59.836\n",
            "Epoch 2458\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.043, rec loss: 0.043, kl: 59.867\n",
            "\t[validation] loss: 0.156, rec loss: 0.156, kl: 59.797\n",
            "Epoch 2459\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.032, rec loss: 0.032, kl: 59.861\n",
            "\t[validation] loss: 0.130, rec loss: 0.130, kl: 59.843\n",
            "Epoch 2460\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 59.877\n",
            "\t[validation] loss: 0.129, rec loss: 0.129, kl: 59.827\n",
            "Epoch 2461\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 59.833\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 59.795\n",
            "Epoch 2462\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.849\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 59.814\n",
            "Epoch 2463\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.866\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 59.849\n",
            "Epoch 2464\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.878\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 59.771\n",
            "Epoch 2465\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 59.869\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 59.840\n",
            "Epoch 2466\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.879\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 59.895\n",
            "Epoch 2467\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 59.911\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 59.845\n",
            "Epoch 2468\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 59.883\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 59.819\n",
            "Epoch 2469\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 59.905\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 59.883\n",
            "Epoch 2470\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.898\n",
            "\t[validation] loss: 0.190, rec loss: 0.190, kl: 59.835\n",
            "Epoch 2471\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.282, rec loss: 1.282, kl: 60.018\n",
            "\t[validation] loss: 0.317, rec loss: 0.317, kl: 60.063\n",
            "Epoch 2472\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.069, rec loss: 0.069, kl: 60.032\n",
            "\t[validation] loss: 0.158, rec loss: 0.158, kl: 59.927\n",
            "Epoch 2473\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.034, rec loss: 0.034, kl: 59.994\n",
            "\t[validation] loss: 0.134, rec loss: 0.134, kl: 59.928\n",
            "Epoch 2474\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 59.977\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 59.903\n",
            "Epoch 2475\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 59.939\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 59.877\n",
            "Epoch 2476\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 59.910\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 59.836\n",
            "Epoch 2477\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 59.899\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 59.907\n",
            "Epoch 2478\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 59.966\n",
            "\t[validation] loss: 0.123, rec loss: 0.123, kl: 59.930\n",
            "Epoch 2479\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.984\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 59.937\n",
            "Epoch 2480\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.008\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 59.918\n",
            "Epoch 2481\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.009\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 59.973\n",
            "Epoch 2482\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 59.978\n",
            "\t[validation] loss: 0.100, rec loss: 0.100, kl: 59.908\n",
            "Epoch 2483\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 59.968\n",
            "\t[validation] loss: 0.253, rec loss: 0.253, kl: 59.803\n",
            "Epoch 2484\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.184, rec loss: 1.184, kl: 60.251\n",
            "\t[validation] loss: 0.232, rec loss: 0.232, kl: 60.135\n",
            "Epoch 2485\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.059, rec loss: 0.059, kl: 60.072\n",
            "\t[validation] loss: 0.174, rec loss: 0.174, kl: 60.082\n",
            "Epoch 2486\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.036, rec loss: 0.036, kl: 60.084\n",
            "\t[validation] loss: 0.134, rec loss: 0.134, kl: 60.082\n",
            "Epoch 2487\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 60.079\n",
            "\t[validation] loss: 0.126, rec loss: 0.126, kl: 59.973\n",
            "Epoch 2488\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 60.012\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 60.033\n",
            "Epoch 2489\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 60.049\n",
            "\t[validation] loss: 0.125, rec loss: 0.125, kl: 60.024\n",
            "Epoch 2490\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 60.074\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 60.009\n",
            "Epoch 2491\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.031\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 60.003\n",
            "Epoch 2492\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.032\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 60.027\n",
            "Epoch 2493\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 60.039\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 60.026\n",
            "Epoch 2494\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 60.110\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 60.136\n",
            "Epoch 2495\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.119\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 60.079\n",
            "Epoch 2496\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.082\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 60.054\n",
            "Epoch 2497\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.124\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 60.170\n",
            "Epoch 2498\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 60.148\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 60.162\n",
            "Epoch 2499\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 60.186\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 60.110\n",
            "Epoch 2500\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.140, rec loss: 0.140, kl: 60.208\n",
            "\t[validation] loss: 5.868, rec loss: 5.868, kl: 60.241\n",
            "Epoch 2501\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.827, rec loss: 1.827, kl: 60.187\n",
            "\t[validation] loss: 0.245, rec loss: 0.245, kl: 60.184\n",
            "Epoch 2502\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.064, rec loss: 0.064, kl: 60.115\n",
            "\t[validation] loss: 0.165, rec loss: 0.165, kl: 60.066\n",
            "Epoch 2503\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.039, rec loss: 0.039, kl: 60.047\n",
            "\t[validation] loss: 0.143, rec loss: 0.143, kl: 60.011\n",
            "Epoch 2504\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 60.012\n",
            "\t[validation] loss: 0.135, rec loss: 0.135, kl: 60.008\n",
            "Epoch 2505\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 60.025\n",
            "\t[validation] loss: 0.129, rec loss: 0.129, kl: 60.065\n",
            "Epoch 2506\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 60.048\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 60.061\n",
            "Epoch 2507\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 60.019\n",
            "\t[validation] loss: 0.119, rec loss: 0.119, kl: 60.043\n",
            "Epoch 2508\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 60.062\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 60.084\n",
            "Epoch 2509\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 60.061\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 60.044\n",
            "Epoch 2510\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 60.061\n",
            "\t[validation] loss: 0.122, rec loss: 0.122, kl: 60.064\n",
            "Epoch 2511\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.027\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 60.050\n",
            "Epoch 2512\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.030\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 60.045\n",
            "Epoch 2513\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.082\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 60.091\n",
            "Epoch 2514\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 60.100\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 60.117\n",
            "Epoch 2515\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 60.067\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 60.042\n",
            "Epoch 2516\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.672, rec loss: 0.672, kl: 60.170\n",
            "\t[validation] loss: 2.523, rec loss: 2.523, kl: 60.673\n",
            "Epoch 2517\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.506, rec loss: 0.506, kl: 60.134\n",
            "\t[validation] loss: 0.197, rec loss: 0.197, kl: 60.031\n",
            "Epoch 2518\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.042, rec loss: 0.042, kl: 60.051\n",
            "\t[validation] loss: 0.149, rec loss: 0.149, kl: 60.017\n",
            "Epoch 2519\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 60.019\n",
            "\t[validation] loss: 0.136, rec loss: 0.136, kl: 59.972\n",
            "Epoch 2520\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 59.969\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 59.952\n",
            "Epoch 2521\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 59.992\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 59.998\n",
            "Epoch 2522\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 59.991\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 59.944\n",
            "Epoch 2523\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 59.961\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 59.945\n",
            "Epoch 2524\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 59.976\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 59.949\n",
            "Epoch 2525\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 59.996\n",
            "\t[validation] loss: 0.100, rec loss: 0.100, kl: 59.972\n",
            "Epoch 2526\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 59.970\n",
            "\t[validation] loss: 0.101, rec loss: 0.101, kl: 59.956\n",
            "Epoch 2527\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 59.990\n",
            "\t[validation] loss: 0.098, rec loss: 0.098, kl: 59.967\n",
            "Epoch 2528\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 59.967\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 59.998\n",
            "Epoch 2529\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 60.023\n",
            "\t[validation] loss: 0.099, rec loss: 0.099, kl: 60.032\n",
            "Epoch 2530\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.010\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 60.079\n",
            "Epoch 2531\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.277, rec loss: 1.277, kl: 60.159\n",
            "\t[validation] loss: 0.573, rec loss: 0.573, kl: 60.337\n",
            "Epoch 2532\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.400, rec loss: 0.400, kl: 60.272\n",
            "\t[validation] loss: 0.194, rec loss: 0.194, kl: 60.115\n",
            "Epoch 2533\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.044, rec loss: 0.044, kl: 60.161\n",
            "\t[validation] loss: 0.153, rec loss: 0.153, kl: 60.100\n",
            "Epoch 2534\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.032, rec loss: 0.032, kl: 60.130\n",
            "\t[validation] loss: 0.129, rec loss: 0.129, kl: 60.051\n",
            "Epoch 2535\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 60.118\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 60.089\n",
            "Epoch 2536\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 60.132\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 60.064\n",
            "Epoch 2537\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 60.127\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 60.059\n",
            "Epoch 2538\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 60.104\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 60.049\n",
            "Epoch 2539\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.110\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 60.063\n",
            "Epoch 2540\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 60.123\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 60.081\n",
            "Epoch 2541\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.120\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 60.097\n",
            "Epoch 2542\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 60.148\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 60.109\n",
            "Epoch 2543\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 60.158\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 60.124\n",
            "Epoch 2544\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 60.175\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 60.079\n",
            "Epoch 2545\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 60.142\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 60.089\n",
            "Epoch 2546\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 60.177\n",
            "\t[validation] loss: 0.346, rec loss: 0.346, kl: 60.155\n",
            "Epoch 2547\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.274, rec loss: 1.274, kl: 60.164\n",
            "\t[validation] loss: 0.204, rec loss: 0.204, kl: 60.115\n",
            "Epoch 2548\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.051, rec loss: 0.051, kl: 60.048\n",
            "\t[validation] loss: 0.154, rec loss: 0.154, kl: 60.054\n",
            "Epoch 2549\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 60.049\n",
            "\t[validation] loss: 0.138, rec loss: 0.138, kl: 60.101\n",
            "Epoch 2550\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 60.105\n",
            "\t[validation] loss: 0.125, rec loss: 0.125, kl: 60.144\n",
            "Epoch 2551\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 60.144\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 60.166\n",
            "Epoch 2552\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.155\n",
            "\t[validation] loss: 0.122, rec loss: 0.122, kl: 60.174\n",
            "Epoch 2553\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 60.139\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 60.156\n",
            "Epoch 2554\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.162\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 60.211\n",
            "Epoch 2555\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.233\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 60.233\n",
            "Epoch 2556\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.237\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 60.210\n",
            "Epoch 2557\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.243\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 60.243\n",
            "Epoch 2558\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.231\n",
            "\t[validation] loss: 0.122, rec loss: 0.122, kl: 60.287\n",
            "Epoch 2559\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.216, rec loss: 1.216, kl: 60.543\n",
            "\t[validation] loss: 0.655, rec loss: 0.655, kl: 60.582\n",
            "Epoch 2560\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.152, rec loss: 0.152, kl: 60.476\n",
            "\t[validation] loss: 0.175, rec loss: 0.175, kl: 60.280\n",
            "Epoch 2561\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.037, rec loss: 0.037, kl: 60.311\n",
            "\t[validation] loss: 0.135, rec loss: 0.135, kl: 60.237\n",
            "Epoch 2562\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 60.292\n",
            "\t[validation] loss: 0.134, rec loss: 0.134, kl: 60.234\n",
            "Epoch 2563\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 60.286\n",
            "\t[validation] loss: 0.119, rec loss: 0.119, kl: 60.313\n",
            "Epoch 2564\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 60.306\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 60.262\n",
            "Epoch 2565\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.293\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 60.258\n",
            "Epoch 2566\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 60.312\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 60.266\n",
            "Epoch 2567\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.283\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 60.269\n",
            "Epoch 2568\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.319\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 60.258\n",
            "Epoch 2569\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.346\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 60.311\n",
            "Epoch 2570\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 60.375\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 60.289\n",
            "Epoch 2571\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.379\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 60.332\n",
            "Epoch 2572\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.380\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 60.316\n",
            "Epoch 2573\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.256, rec loss: 1.256, kl: 60.460\n",
            "\t[validation] loss: 2.236, rec loss: 2.236, kl: 60.682\n",
            "Epoch 2574\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.343, rec loss: 0.343, kl: 60.640\n",
            "\t[validation] loss: 0.780, rec loss: 0.780, kl: 60.502\n",
            "Epoch 2575\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.084, rec loss: 0.084, kl: 60.383\n",
            "\t[validation] loss: 0.169, rec loss: 0.169, kl: 60.270\n",
            "Epoch 2576\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 60.328\n",
            "\t[validation] loss: 0.140, rec loss: 0.140, kl: 60.253\n",
            "Epoch 2577\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 60.312\n",
            "\t[validation] loss: 0.129, rec loss: 0.129, kl: 60.271\n",
            "Epoch 2578\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 60.335\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 60.257\n",
            "Epoch 2579\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 60.353\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 60.275\n",
            "Epoch 2580\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.325\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 60.256\n",
            "Epoch 2581\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.363\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 60.270\n",
            "Epoch 2582\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 60.371\n",
            "\t[validation] loss: 0.137, rec loss: 0.137, kl: 60.285\n",
            "Epoch 2583\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.353\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 60.300\n",
            "Epoch 2584\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.372\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 60.323\n",
            "Epoch 2585\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.412\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 60.366\n",
            "Epoch 2586\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.431\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 60.370\n",
            "Epoch 2587\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 60.423\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 60.378\n",
            "Epoch 2588\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 60.451\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 60.388\n",
            "Epoch 2589\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.042, rec loss: 0.042, kl: 60.457\n",
            "\t[validation] loss: 0.637, rec loss: 0.637, kl: 60.652\n",
            "Epoch 2590\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.508, rec loss: 1.508, kl: 60.726\n",
            "\t[validation] loss: 0.277, rec loss: 0.277, kl: 60.669\n",
            "Epoch 2591\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.287, rec loss: 0.287, kl: 60.438\n",
            "\t[validation] loss: 0.233, rec loss: 0.233, kl: 60.283\n",
            "Epoch 2592\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.045, rec loss: 0.045, kl: 60.277\n",
            "\t[validation] loss: 0.148, rec loss: 0.148, kl: 60.272\n",
            "Epoch 2593\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 60.279\n",
            "\t[validation] loss: 0.129, rec loss: 0.129, kl: 60.263\n",
            "Epoch 2594\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 60.260\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 60.273\n",
            "Epoch 2595\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 60.289\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 60.252\n",
            "Epoch 2596\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 60.261\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 60.247\n",
            "Epoch 2597\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.265\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 60.267\n",
            "Epoch 2598\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.280\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 60.264\n",
            "Epoch 2599\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 60.306\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 60.289\n",
            "Epoch 2600\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.308\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 60.335\n",
            "Epoch 2601\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 60.366\n",
            "\t[validation] loss: 0.099, rec loss: 0.099, kl: 60.326\n",
            "Epoch 2602\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 60.336\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 60.291\n",
            "Epoch 2603\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 60.322\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 60.228\n",
            "Epoch 2604\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 60.353\n",
            "\t[validation] loss: 0.100, rec loss: 0.100, kl: 60.323\n",
            "Epoch 2605\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.128, rec loss: 1.128, kl: 60.609\n",
            "\t[validation] loss: 0.635, rec loss: 0.635, kl: 60.758\n",
            "Epoch 2606\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.085, rec loss: 0.085, kl: 60.563\n",
            "\t[validation] loss: 0.166, rec loss: 0.166, kl: 60.508\n",
            "Epoch 2607\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.036, rec loss: 0.036, kl: 60.484\n",
            "\t[validation] loss: 0.148, rec loss: 0.148, kl: 60.481\n",
            "Epoch 2608\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 60.494\n",
            "\t[validation] loss: 0.131, rec loss: 0.131, kl: 60.529\n",
            "Epoch 2609\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 60.464\n",
            "\t[validation] loss: 0.126, rec loss: 0.126, kl: 60.460\n",
            "Epoch 2610\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 60.472\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 60.481\n",
            "Epoch 2611\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.473\n",
            "\t[validation] loss: 0.122, rec loss: 0.122, kl: 60.486\n",
            "Epoch 2612\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 60.464\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 60.449\n",
            "Epoch 2613\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.487\n",
            "\t[validation] loss: 0.119, rec loss: 0.119, kl: 60.468\n",
            "Epoch 2614\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.461\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 60.460\n",
            "Epoch 2615\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 60.484\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 60.509\n",
            "Epoch 2616\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.510\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 60.519\n",
            "Epoch 2617\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.491\n",
            "\t[validation] loss: 0.502, rec loss: 0.502, kl: 60.459\n",
            "Epoch 2618\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.613, rec loss: 0.613, kl: 60.739\n",
            "\t[validation] loss: 0.236, rec loss: 0.236, kl: 60.713\n",
            "Epoch 2619\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.037, rec loss: 0.037, kl: 60.714\n",
            "\t[validation] loss: 0.141, rec loss: 0.141, kl: 60.563\n",
            "Epoch 2620\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 60.629\n",
            "\t[validation] loss: 0.127, rec loss: 0.127, kl: 60.563\n",
            "Epoch 2621\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 60.625\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 60.557\n",
            "Epoch 2622\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.481, rec loss: 0.481, kl: 60.709\n",
            "\t[validation] loss: 1.048, rec loss: 1.048, kl: 60.853\n",
            "Epoch 2623\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.743, rec loss: 0.743, kl: 60.988\n",
            "\t[validation] loss: 0.218, rec loss: 0.218, kl: 60.859\n",
            "Epoch 2624\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.044, rec loss: 0.044, kl: 60.839\n",
            "\t[validation] loss: 0.151, rec loss: 0.151, kl: 60.732\n",
            "Epoch 2625\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 60.780\n",
            "\t[validation] loss: 0.131, rec loss: 0.131, kl: 60.676\n",
            "Epoch 2626\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 60.743\n",
            "\t[validation] loss: 0.129, rec loss: 0.129, kl: 60.682\n",
            "Epoch 2627\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 60.735\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 60.645\n",
            "Epoch 2628\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.723\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 60.623\n",
            "Epoch 2629\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 60.695\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 60.658\n",
            "Epoch 2630\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.695\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 60.636\n",
            "Epoch 2631\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 60.705\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 60.655\n",
            "Epoch 2632\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.724\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 60.651\n",
            "Epoch 2633\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 60.715\n",
            "\t[validation] loss: 0.129, rec loss: 0.129, kl: 60.619\n",
            "Epoch 2634\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 60.700\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 60.642\n",
            "Epoch 2635\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 60.675\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 60.590\n",
            "Epoch 2636\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 60.689\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 60.635\n",
            "Epoch 2637\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.670, rec loss: 0.670, kl: 60.867\n",
            "\t[validation] loss: 1.097, rec loss: 1.097, kl: 61.111\n",
            "Epoch 2638\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.189, rec loss: 0.189, kl: 60.857\n",
            "\t[validation] loss: 0.189, rec loss: 0.189, kl: 60.628\n",
            "Epoch 2639\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.035, rec loss: 0.035, kl: 60.723\n",
            "\t[validation] loss: 0.148, rec loss: 0.148, kl: 60.648\n",
            "Epoch 2640\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 60.699\n",
            "\t[validation] loss: 0.133, rec loss: 0.133, kl: 60.648\n",
            "Epoch 2641\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 60.719\n",
            "\t[validation] loss: 0.127, rec loss: 0.127, kl: 60.618\n",
            "Epoch 2642\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 60.708\n",
            "\t[validation] loss: 0.123, rec loss: 0.123, kl: 60.683\n",
            "Epoch 2643\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.738\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 60.683\n",
            "Epoch 2644\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 60.731\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 60.661\n",
            "Epoch 2645\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 60.689\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 60.657\n",
            "Epoch 2646\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 60.687\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 60.622\n",
            "Epoch 2647\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 60.707\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 60.635\n",
            "Epoch 2648\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.733\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 60.735\n",
            "Epoch 2649\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.567, rec loss: 1.567, kl: 61.014\n",
            "\t[validation] loss: 0.824, rec loss: 0.824, kl: 61.147\n",
            "Epoch 2650\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.142, rec loss: 0.142, kl: 60.927\n",
            "\t[validation] loss: 0.179, rec loss: 0.179, kl: 60.788\n",
            "Epoch 2651\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.040, rec loss: 0.040, kl: 60.806\n",
            "\t[validation] loss: 0.155, rec loss: 0.155, kl: 60.712\n",
            "Epoch 2652\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 60.741\n",
            "\t[validation] loss: 0.134, rec loss: 0.134, kl: 60.678\n",
            "Epoch 2653\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 60.728\n",
            "\t[validation] loss: 0.126, rec loss: 0.126, kl: 60.682\n",
            "Epoch 2654\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 60.746\n",
            "\t[validation] loss: 0.119, rec loss: 0.119, kl: 60.706\n",
            "Epoch 2655\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 60.781\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 60.723\n",
            "Epoch 2656\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.760\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 60.691\n",
            "Epoch 2657\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.774\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 60.726\n",
            "Epoch 2658\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.762\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 60.754\n",
            "Epoch 2659\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.765\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 60.677\n",
            "Epoch 2660\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.770\n",
            "\t[validation] loss: 0.127, rec loss: 0.127, kl: 60.815\n",
            "Epoch 2661\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.839\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 60.748\n",
            "Epoch 2662\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.804\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 60.735\n",
            "Epoch 2663\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 60.832\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 60.767\n",
            "Epoch 2664\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.817\n",
            "\t[validation] loss: 0.123, rec loss: 0.123, kl: 60.827\n",
            "Epoch 2665\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 60.868\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 60.879\n",
            "Epoch 2666\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.911\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 60.892\n",
            "Epoch 2667\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.501, rec loss: 1.501, kl: 61.022\n",
            "\t[validation] loss: 1.380, rec loss: 1.380, kl: 61.101\n",
            "Epoch 2668\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.267, rec loss: 0.267, kl: 60.866\n",
            "\t[validation] loss: 0.198, rec loss: 0.198, kl: 60.785\n",
            "Epoch 2669\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.043, rec loss: 0.043, kl: 60.806\n",
            "\t[validation] loss: 0.151, rec loss: 0.151, kl: 60.727\n",
            "Epoch 2670\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 60.806\n",
            "\t[validation] loss: 0.136, rec loss: 0.136, kl: 60.744\n",
            "Epoch 2671\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 60.788\n",
            "\t[validation] loss: 0.125, rec loss: 0.125, kl: 60.723\n",
            "Epoch 2672\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 60.795\n",
            "\t[validation] loss: 0.119, rec loss: 0.119, kl: 60.732\n",
            "Epoch 2673\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.805\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 60.718\n",
            "Epoch 2674\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.772\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 60.735\n",
            "Epoch 2675\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.818\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 60.744\n",
            "Epoch 2676\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.842\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 60.764\n",
            "Epoch 2677\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.855\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 60.813\n",
            "Epoch 2678\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.874\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 60.779\n",
            "Epoch 2679\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.894\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 60.822\n",
            "Epoch 2680\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 60.903\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 60.779\n",
            "Epoch 2681\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 60.931\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 60.921\n",
            "Epoch 2682\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 60.976\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 60.886\n",
            "Epoch 2683\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.116, rec loss: 1.116, kl: 61.019\n",
            "\t[validation] loss: 4.602, rec loss: 4.602, kl: 61.427\n",
            "Epoch 2684\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.456, rec loss: 0.456, kl: 61.042\n",
            "\t[validation] loss: 0.191, rec loss: 0.191, kl: 60.940\n",
            "Epoch 2685\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.041, rec loss: 0.041, kl: 60.902\n",
            "\t[validation] loss: 0.149, rec loss: 0.149, kl: 60.876\n",
            "Epoch 2686\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 60.877\n",
            "\t[validation] loss: 0.131, rec loss: 0.131, kl: 60.847\n",
            "Epoch 2687\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 60.846\n",
            "\t[validation] loss: 0.126, rec loss: 0.126, kl: 60.853\n",
            "Epoch 2688\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 60.839\n",
            "\t[validation] loss: 0.122, rec loss: 0.122, kl: 60.817\n",
            "Epoch 2689\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.816\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 60.774\n",
            "Epoch 2690\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.815\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 60.808\n",
            "Epoch 2691\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 60.837\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 60.793\n",
            "Epoch 2692\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 60.847\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 60.830\n",
            "Epoch 2693\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.870\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 60.828\n",
            "Epoch 2694\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 60.917\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 60.929\n",
            "Epoch 2695\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 60.928\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 60.909\n",
            "Epoch 2696\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 60.918\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 60.882\n",
            "Epoch 2697\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 60.940\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 60.907\n",
            "Epoch 2698\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 60.992\n",
            "\t[validation] loss: 0.127, rec loss: 0.127, kl: 60.957\n",
            "Epoch 2699\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.467, rec loss: 0.467, kl: 61.022\n",
            "\t[validation] loss: 2.695, rec loss: 2.695, kl: 61.209\n",
            "Epoch 2700\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.293, rec loss: 1.293, kl: 61.246\n",
            "\t[validation] loss: 0.284, rec loss: 0.284, kl: 61.081\n",
            "Epoch 2701\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.064, rec loss: 0.064, kl: 61.062\n",
            "\t[validation] loss: 0.170, rec loss: 0.170, kl: 60.953\n",
            "Epoch 2702\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.035, rec loss: 0.035, kl: 60.990\n",
            "\t[validation] loss: 0.144, rec loss: 0.144, kl: 60.973\n",
            "Epoch 2703\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 60.985\n",
            "\t[validation] loss: 0.134, rec loss: 0.134, kl: 60.948\n",
            "Epoch 2704\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 60.938\n",
            "\t[validation] loss: 0.127, rec loss: 0.127, kl: 60.907\n",
            "Epoch 2705\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 60.950\n",
            "\t[validation] loss: 0.122, rec loss: 0.122, kl: 60.933\n",
            "Epoch 2706\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.949\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 60.940\n",
            "Epoch 2707\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.944\n",
            "\t[validation] loss: 0.123, rec loss: 0.123, kl: 60.915\n",
            "Epoch 2708\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 60.945\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 60.923\n",
            "Epoch 2709\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 60.961\n",
            "\t[validation] loss: 0.155, rec loss: 0.155, kl: 60.932\n",
            "Epoch 2710\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 60.956\n",
            "\t[validation] loss: 0.136, rec loss: 0.136, kl: 60.888\n",
            "Epoch 2711\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 60.939\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 60.927\n",
            "Epoch 2712\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 60.924\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 60.863\n",
            "Epoch 2713\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 60.976\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 60.968\n",
            "Epoch 2714\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 61.055\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 61.083\n",
            "Epoch 2715\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.086\n",
            "\t[validation] loss: 0.097, rec loss: 0.097, kl: 61.096\n",
            "Epoch 2716\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.122\n",
            "\t[validation] loss: 0.101, rec loss: 0.101, kl: 61.114\n",
            "Epoch 2717\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.107\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 61.074\n",
            "Epoch 2718\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.087\n",
            "\t[validation] loss: 0.127, rec loss: 0.127, kl: 61.025\n",
            "Epoch 2719\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.572, rec loss: 1.572, kl: 61.433\n",
            "\t[validation] loss: 0.262, rec loss: 0.262, kl: 61.421\n",
            "Epoch 2720\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.064, rec loss: 0.064, kl: 61.353\n",
            "\t[validation] loss: 0.162, rec loss: 0.162, kl: 61.262\n",
            "Epoch 2721\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.035, rec loss: 0.035, kl: 61.272\n",
            "\t[validation] loss: 0.133, rec loss: 0.133, kl: 61.219\n",
            "Epoch 2722\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 61.224\n",
            "\t[validation] loss: 0.129, rec loss: 0.129, kl: 61.174\n",
            "Epoch 2723\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 61.210\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 61.136\n",
            "Epoch 2724\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 61.216\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 61.324\n",
            "Epoch 2725\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 61.301\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 61.338\n",
            "Epoch 2726\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 61.341\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 61.378\n",
            "Epoch 2727\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 61.359\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 61.376\n",
            "Epoch 2728\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 61.369\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 61.357\n",
            "Epoch 2729\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.384\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 61.383\n",
            "Epoch 2730\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.401\n",
            "\t[validation] loss: 0.099, rec loss: 0.099, kl: 61.374\n",
            "Epoch 2731\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.406\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 61.386\n",
            "Epoch 2732\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 61.390\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 61.321\n",
            "Epoch 2733\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.408, rec loss: 1.408, kl: 61.449\n",
            "\t[validation] loss: 0.245, rec loss: 0.245, kl: 61.321\n",
            "Epoch 2734\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.059, rec loss: 0.059, kl: 61.295\n",
            "\t[validation] loss: 0.160, rec loss: 0.160, kl: 61.213\n",
            "Epoch 2735\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 61.207\n",
            "\t[validation] loss: 0.139, rec loss: 0.139, kl: 61.161\n",
            "Epoch 2736\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 61.194\n",
            "\t[validation] loss: 0.122, rec loss: 0.122, kl: 61.178\n",
            "Epoch 2737\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 61.201\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 61.165\n",
            "Epoch 2738\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 61.227\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 61.207\n",
            "Epoch 2739\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 61.213\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 61.180\n",
            "Epoch 2740\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 61.176\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 61.158\n",
            "Epoch 2741\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.164\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 61.157\n",
            "Epoch 2742\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 61.166\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 61.197\n",
            "Epoch 2743\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.205\n",
            "\t[validation] loss: 0.097, rec loss: 0.097, kl: 61.217\n",
            "Epoch 2744\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.192\n",
            "\t[validation] loss: 0.098, rec loss: 0.098, kl: 61.197\n",
            "Epoch 2745\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.776, rec loss: 0.776, kl: 61.274\n",
            "\t[validation] loss: 2.997, rec loss: 2.997, kl: 61.991\n",
            "Epoch 2746\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.548, rec loss: 0.548, kl: 61.690\n",
            "\t[validation] loss: 0.197, rec loss: 0.197, kl: 61.516\n",
            "Epoch 2747\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.041, rec loss: 0.041, kl: 61.521\n",
            "\t[validation] loss: 0.153, rec loss: 0.153, kl: 61.440\n",
            "Epoch 2748\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 61.412\n",
            "\t[validation] loss: 0.128, rec loss: 0.128, kl: 61.389\n",
            "Epoch 2749\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 61.402\n",
            "\t[validation] loss: 0.122, rec loss: 0.122, kl: 61.383\n",
            "Epoch 2750\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 61.407\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 61.375\n",
            "Epoch 2751\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 61.392\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 61.356\n",
            "Epoch 2752\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 61.369\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 61.363\n",
            "Epoch 2753\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 61.382\n",
            "\t[validation] loss: 0.144, rec loss: 0.144, kl: 61.394\n",
            "Epoch 2754\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 61.380\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 61.357\n",
            "Epoch 2755\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.342\n",
            "\t[validation] loss: 0.101, rec loss: 0.101, kl: 61.337\n",
            "Epoch 2756\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.375\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 61.342\n",
            "Epoch 2757\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.383\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 61.382\n",
            "Epoch 2758\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.390\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 61.378\n",
            "Epoch 2759\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.408\n",
            "\t[validation] loss: 0.099, rec loss: 0.099, kl: 61.379\n",
            "Epoch 2760\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.374\n",
            "\t[validation] loss: 0.122, rec loss: 0.122, kl: 61.397\n",
            "Epoch 2761\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.462\n",
            "\t[validation] loss: 0.098, rec loss: 0.098, kl: 61.460\n",
            "Epoch 2762\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.467\n",
            "\t[validation] loss: 0.099, rec loss: 0.099, kl: 61.444\n",
            "Epoch 2763\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.012, rec loss: 0.012, kl: 61.463\n",
            "\t[validation] loss: 0.173, rec loss: 0.173, kl: 61.459\n",
            "Epoch 2764\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 2.104, rec loss: 2.104, kl: 61.811\n",
            "\t[validation] loss: 0.348, rec loss: 0.348, kl: 61.724\n",
            "Epoch 2765\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.092, rec loss: 0.092, kl: 61.658\n",
            "\t[validation] loss: 0.171, rec loss: 0.171, kl: 61.696\n",
            "Epoch 2766\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.041, rec loss: 0.041, kl: 61.651\n",
            "\t[validation] loss: 0.140, rec loss: 0.140, kl: 61.713\n",
            "Epoch 2767\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.029, rec loss: 0.029, kl: 61.660\n",
            "\t[validation] loss: 0.132, rec loss: 0.132, kl: 61.691\n",
            "Epoch 2768\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 61.649\n",
            "\t[validation] loss: 0.123, rec loss: 0.123, kl: 61.635\n",
            "Epoch 2769\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 61.622\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 61.629\n",
            "Epoch 2770\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 61.605\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 61.620\n",
            "Epoch 2771\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 61.578\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 61.571\n",
            "Epoch 2772\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 61.554\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 61.575\n",
            "Epoch 2773\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 61.571\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 61.549\n",
            "Epoch 2774\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.537\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 61.546\n",
            "Epoch 2775\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.525\n",
            "\t[validation] loss: 0.101, rec loss: 0.101, kl: 61.521\n",
            "Epoch 2776\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 61.607\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 61.621\n",
            "Epoch 2777\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.597\n",
            "\t[validation] loss: 0.101, rec loss: 0.101, kl: 61.618\n",
            "Epoch 2778\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 61.581\n",
            "\t[validation] loss: 0.100, rec loss: 0.100, kl: 61.617\n",
            "Epoch 2779\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.601\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 61.663\n",
            "Epoch 2780\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.404, rec loss: 0.404, kl: 61.594\n",
            "\t[validation] loss: 3.377, rec loss: 3.377, kl: 61.669\n",
            "Epoch 2781\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.947, rec loss: 0.947, kl: 61.597\n",
            "\t[validation] loss: 0.190, rec loss: 0.190, kl: 61.589\n",
            "Epoch 2782\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.043, rec loss: 0.043, kl: 61.533\n",
            "\t[validation] loss: 0.149, rec loss: 0.149, kl: 61.557\n",
            "Epoch 2783\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 61.497\n",
            "\t[validation] loss: 0.129, rec loss: 0.129, kl: 61.500\n",
            "Epoch 2784\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 61.479\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 61.500\n",
            "Epoch 2785\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 61.449\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 61.456\n",
            "Epoch 2786\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 61.416\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 61.432\n",
            "Epoch 2787\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 61.425\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 61.450\n",
            "Epoch 2788\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 61.391\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 61.441\n",
            "Epoch 2789\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 61.399\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 61.432\n",
            "Epoch 2790\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.418\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 61.408\n",
            "Epoch 2791\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.372\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 61.417\n",
            "Epoch 2792\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.431\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 61.463\n",
            "Epoch 2793\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.446\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 61.474\n",
            "Epoch 2794\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.446\n",
            "\t[validation] loss: 0.099, rec loss: 0.099, kl: 61.465\n",
            "Epoch 2795\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.429\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 61.493\n",
            "Epoch 2796\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.926, rec loss: 0.926, kl: 61.606\n",
            "\t[validation] loss: 0.832, rec loss: 0.832, kl: 61.976\n",
            "Epoch 2797\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.176, rec loss: 0.176, kl: 61.772\n",
            "\t[validation] loss: 0.170, rec loss: 0.170, kl: 61.661\n",
            "Epoch 2798\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.033, rec loss: 0.033, kl: 61.659\n",
            "\t[validation] loss: 0.140, rec loss: 0.140, kl: 61.620\n",
            "Epoch 2799\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 61.608\n",
            "\t[validation] loss: 0.127, rec loss: 0.127, kl: 61.522\n",
            "Epoch 2800\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 61.582\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 61.528\n",
            "Epoch 2801\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 61.529\n",
            "\t[validation] loss: 0.122, rec loss: 0.122, kl: 61.512\n",
            "Epoch 2802\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 61.520\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 61.487\n",
            "Epoch 2803\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.515\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 61.461\n",
            "Epoch 2804\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.518\n",
            "\t[validation] loss: 0.100, rec loss: 0.100, kl: 61.496\n",
            "Epoch 2805\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.535\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 61.520\n",
            "Epoch 2806\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.570\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 61.539\n",
            "Epoch 2807\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.580\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 61.548\n",
            "Epoch 2808\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.587\n",
            "\t[validation] loss: 0.100, rec loss: 0.100, kl: 61.547\n",
            "Epoch 2809\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.577\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 61.558\n",
            "Epoch 2810\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.132, rec loss: 1.132, kl: 61.644\n",
            "\t[validation] loss: 0.382, rec loss: 0.382, kl: 61.701\n",
            "Epoch 2811\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.069, rec loss: 0.069, kl: 61.583\n",
            "\t[validation] loss: 0.158, rec loss: 0.158, kl: 61.523\n",
            "Epoch 2812\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 61.497\n",
            "\t[validation] loss: 0.136, rec loss: 0.136, kl: 61.416\n",
            "Epoch 2813\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 61.426\n",
            "\t[validation] loss: 0.127, rec loss: 0.127, kl: 61.361\n",
            "Epoch 2814\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 61.419\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 61.439\n",
            "Epoch 2815\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 61.396\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 61.391\n",
            "Epoch 2816\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.360\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 61.357\n",
            "Epoch 2817\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.369\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 61.352\n",
            "Epoch 2818\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.364\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 61.364\n",
            "Epoch 2819\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.395\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 61.383\n",
            "Epoch 2820\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.375\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 61.313\n",
            "Epoch 2821\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.302, rec loss: 1.302, kl: 61.672\n",
            "\t[validation] loss: 0.398, rec loss: 0.398, kl: 61.851\n",
            "Epoch 2822\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.593, rec loss: 0.593, kl: 61.817\n",
            "\t[validation] loss: 0.266, rec loss: 0.266, kl: 61.834\n",
            "Epoch 2823\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.058, rec loss: 0.058, kl: 61.841\n",
            "\t[validation] loss: 0.159, rec loss: 0.159, kl: 61.717\n",
            "Epoch 2824\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 61.738\n",
            "\t[validation] loss: 0.136, rec loss: 0.136, kl: 61.664\n",
            "Epoch 2825\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 61.687\n",
            "\t[validation] loss: 0.131, rec loss: 0.131, kl: 61.634\n",
            "Epoch 2826\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 61.649\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 61.576\n",
            "Epoch 2827\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 61.615\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 61.584\n",
            "Epoch 2828\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 61.646\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 61.597\n",
            "Epoch 2829\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 61.633\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 61.550\n",
            "Epoch 2830\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 61.591\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 61.544\n",
            "Epoch 2831\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 61.575\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 61.546\n",
            "Epoch 2832\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.584\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 61.540\n",
            "Epoch 2833\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.576\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 61.523\n",
            "Epoch 2834\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.560\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 61.511\n",
            "Epoch 2835\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.531\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 61.494\n",
            "Epoch 2836\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.011, rec loss: 0.011, kl: 61.540\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 61.471\n",
            "Epoch 2837\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.012, rec loss: 0.012, kl: 61.549\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 61.505\n",
            "Epoch 2838\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.587\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 61.602\n",
            "Epoch 2839\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.012, rec loss: 0.012, kl: 61.623\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 61.544\n",
            "Epoch 2840\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.093, rec loss: 1.093, kl: 61.783\n",
            "\t[validation] loss: 1.788, rec loss: 1.788, kl: 61.946\n",
            "Epoch 2841\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.210, rec loss: 0.210, kl: 61.641\n",
            "\t[validation] loss: 0.193, rec loss: 0.193, kl: 61.496\n",
            "Epoch 2842\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.038, rec loss: 0.038, kl: 61.537\n",
            "\t[validation] loss: 0.150, rec loss: 0.150, kl: 61.502\n",
            "Epoch 2843\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 61.552\n",
            "\t[validation] loss: 0.131, rec loss: 0.131, kl: 61.550\n",
            "Epoch 2844\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 61.524\n",
            "\t[validation] loss: 0.129, rec loss: 0.129, kl: 61.482\n",
            "Epoch 2845\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 61.521\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 61.557\n",
            "Epoch 2846\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 61.543\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 61.503\n",
            "Epoch 2847\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.511\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 61.480\n",
            "Epoch 2848\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 61.491\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 61.489\n",
            "Epoch 2849\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.522\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 61.485\n",
            "Epoch 2850\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.526\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 61.512\n",
            "Epoch 2851\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.528\n",
            "\t[validation] loss: 0.126, rec loss: 0.126, kl: 61.529\n",
            "Epoch 2852\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.545\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 61.472\n",
            "Epoch 2853\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.490\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 61.448\n",
            "Epoch 2854\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.513\n",
            "\t[validation] loss: 0.101, rec loss: 0.101, kl: 61.447\n",
            "Epoch 2855\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.012, rec loss: 0.012, kl: 61.507\n",
            "\t[validation] loss: 0.101, rec loss: 0.101, kl: 61.494\n",
            "Epoch 2856\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.011, rec loss: 0.011, kl: 61.543\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 61.476\n",
            "Epoch 2857\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.689, rec loss: 0.689, kl: 61.669\n",
            "\t[validation] loss: 1.607, rec loss: 1.607, kl: 61.898\n",
            "Epoch 2858\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.532, rec loss: 0.532, kl: 61.761\n",
            "\t[validation] loss: 0.195, rec loss: 0.195, kl: 61.601\n",
            "Epoch 2859\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.038, rec loss: 0.038, kl: 61.583\n",
            "\t[validation] loss: 0.142, rec loss: 0.142, kl: 61.542\n",
            "Epoch 2860\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 61.549\n",
            "\t[validation] loss: 0.129, rec loss: 0.129, kl: 61.487\n",
            "Epoch 2861\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 61.501\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 61.475\n",
            "Epoch 2862\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 61.510\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 61.493\n",
            "Epoch 2863\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 61.501\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 61.473\n",
            "Epoch 2864\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.479\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 61.455\n",
            "Epoch 2865\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.489\n",
            "\t[validation] loss: 0.101, rec loss: 0.101, kl: 61.461\n",
            "Epoch 2866\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.545\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 61.504\n",
            "Epoch 2867\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.012, rec loss: 0.012, kl: 61.553\n",
            "\t[validation] loss: 0.095, rec loss: 0.095, kl: 61.496\n",
            "Epoch 2868\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.559\n",
            "\t[validation] loss: 0.097, rec loss: 0.097, kl: 61.533\n",
            "Epoch 2869\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.565\n",
            "\t[validation] loss: 0.101, rec loss: 0.101, kl: 61.550\n",
            "Epoch 2870\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.581\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 61.561\n",
            "Epoch 2871\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.584\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 61.505\n",
            "Epoch 2872\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.579\n",
            "\t[validation] loss: 0.126, rec loss: 0.126, kl: 61.558\n",
            "Epoch 2873\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 61.585\n",
            "\t[validation] loss: 0.311, rec loss: 0.311, kl: 61.522\n",
            "Epoch 2874\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.651, rec loss: 1.651, kl: 61.866\n",
            "\t[validation] loss: 0.236, rec loss: 0.236, kl: 61.469\n",
            "Epoch 2875\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.252, rec loss: 0.252, kl: 61.371\n",
            "\t[validation] loss: 0.363, rec loss: 0.363, kl: 61.155\n",
            "Epoch 2876\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.065, rec loss: 0.065, kl: 61.222\n",
            "\t[validation] loss: 0.153, rec loss: 0.153, kl: 61.148\n",
            "Epoch 2877\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.039, rec loss: 0.039, kl: 61.257\n",
            "\t[validation] loss: 0.136, rec loss: 0.136, kl: 61.215\n",
            "Epoch 2878\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 61.267\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 61.216\n",
            "Epoch 2879\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.026, rec loss: 0.026, kl: 61.258\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 61.203\n",
            "Epoch 2880\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 61.260\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 61.194\n",
            "Epoch 2881\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 61.248\n",
            "\t[validation] loss: 0.140, rec loss: 0.140, kl: 61.198\n",
            "Epoch 2882\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 61.246\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 61.241\n",
            "Epoch 2883\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 61.258\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 61.186\n",
            "Epoch 2884\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 61.276\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 61.246\n",
            "Epoch 2885\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.750, rec loss: 0.750, kl: 61.327\n",
            "\t[validation] loss: 1.509, rec loss: 1.509, kl: 61.662\n",
            "Epoch 2886\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.216, rec loss: 0.216, kl: 61.613\n",
            "\t[validation] loss: 0.202, rec loss: 0.202, kl: 61.520\n",
            "Epoch 2887\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.043, rec loss: 0.043, kl: 61.499\n",
            "\t[validation] loss: 0.147, rec loss: 0.147, kl: 61.488\n",
            "Epoch 2888\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 61.497\n",
            "\t[validation] loss: 0.130, rec loss: 0.130, kl: 61.453\n",
            "Epoch 2889\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 61.453\n",
            "\t[validation] loss: 0.125, rec loss: 0.125, kl: 61.402\n",
            "Epoch 2890\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 61.423\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 61.406\n",
            "Epoch 2891\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 61.465\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 61.393\n",
            "Epoch 2892\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 61.420\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 61.371\n",
            "Epoch 2893\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 61.404\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 61.371\n",
            "Epoch 2894\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 61.421\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 61.387\n",
            "Epoch 2895\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 61.462\n",
            "\t[validation] loss: 0.112, rec loss: 0.112, kl: 61.401\n",
            "Epoch 2896\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.448\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 61.399\n",
            "Epoch 2897\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.458\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 61.439\n",
            "Epoch 2898\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.496\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 61.470\n",
            "Epoch 2899\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.539\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 61.489\n",
            "Epoch 2900\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.859, rec loss: 0.859, kl: 61.655\n",
            "\t[validation] loss: 5.157, rec loss: 5.157, kl: 62.249\n",
            "Epoch 2901\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.550, rec loss: 0.550, kl: 62.235\n",
            "\t[validation] loss: 0.192, rec loss: 0.192, kl: 62.162\n",
            "Epoch 2902\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.043, rec loss: 0.043, kl: 62.072\n",
            "\t[validation] loss: 0.154, rec loss: 0.154, kl: 62.092\n",
            "Epoch 2903\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.030, rec loss: 0.030, kl: 62.059\n",
            "\t[validation] loss: 0.138, rec loss: 0.138, kl: 62.051\n",
            "Epoch 2904\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 62.024\n",
            "\t[validation] loss: 0.131, rec loss: 0.131, kl: 62.007\n",
            "Epoch 2905\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 62.077\n",
            "\t[validation] loss: 0.121, rec loss: 0.121, kl: 62.092\n",
            "Epoch 2906\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 62.060\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 62.067\n",
            "Epoch 2907\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 62.048\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 62.053\n",
            "Epoch 2908\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 62.078\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 62.077\n",
            "Epoch 2909\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 62.084\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 62.091\n",
            "Epoch 2910\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 62.069\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 62.096\n",
            "Epoch 2911\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 62.046\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 62.042\n",
            "Epoch 2912\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 62.045\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 62.049\n",
            "Epoch 2913\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 62.073\n",
            "\t[validation] loss: 0.124, rec loss: 0.124, kl: 62.073\n",
            "Epoch 2914\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 62.072\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 62.098\n",
            "Epoch 2915\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 62.087\n",
            "\t[validation] loss: 0.181, rec loss: 0.181, kl: 62.179\n",
            "Epoch 2916\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.882, rec loss: 0.882, kl: 62.308\n",
            "\t[validation] loss: 0.198, rec loss: 0.198, kl: 62.264\n",
            "Epoch 2917\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.042, rec loss: 0.042, kl: 62.176\n",
            "\t[validation] loss: 0.140, rec loss: 0.140, kl: 62.143\n",
            "Epoch 2918\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 62.138\n",
            "\t[validation] loss: 0.123, rec loss: 0.123, kl: 62.140\n",
            "Epoch 2919\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.021, rec loss: 0.021, kl: 62.117\n",
            "\t[validation] loss: 0.117, rec loss: 0.117, kl: 62.096\n",
            "Epoch 2920\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 62.117\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 62.130\n",
            "Epoch 2921\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 62.127\n",
            "\t[validation] loss: 0.105, rec loss: 0.105, kl: 62.120\n",
            "Epoch 2922\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 62.130\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 62.192\n",
            "Epoch 2923\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 62.183\n",
            "\t[validation] loss: 0.110, rec loss: 0.110, kl: 62.200\n",
            "Epoch 2924\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 62.181\n",
            "\t[validation] loss: 0.098, rec loss: 0.098, kl: 62.168\n",
            "Epoch 2925\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 62.148\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 62.136\n",
            "Epoch 2926\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 62.138\n",
            "\t[validation] loss: 0.100, rec loss: 0.100, kl: 62.124\n",
            "Epoch 2927\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 62.126\n",
            "\t[validation] loss: 0.100, rec loss: 0.100, kl: 62.142\n",
            "Epoch 2928\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.085, rec loss: 0.085, kl: 62.095\n",
            "\t[validation] loss: 3.604, rec loss: 3.604, kl: 62.128\n",
            "Epoch 2929\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.221, rec loss: 1.221, kl: 62.420\n",
            "\t[validation] loss: 0.213, rec loss: 0.213, kl: 62.311\n",
            "Epoch 2930\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.051, rec loss: 0.051, kl: 62.250\n",
            "\t[validation] loss: 0.157, rec loss: 0.157, kl: 62.152\n",
            "Epoch 2931\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.031, rec loss: 0.031, kl: 62.167\n",
            "\t[validation] loss: 0.129, rec loss: 0.129, kl: 62.083\n",
            "Epoch 2932\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 62.128\n",
            "\t[validation] loss: 0.122, rec loss: 0.122, kl: 62.118\n",
            "Epoch 2933\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 62.137\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 62.061\n",
            "Epoch 2934\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 62.093\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 62.069\n",
            "Epoch 2935\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 62.101\n",
            "\t[validation] loss: 0.104, rec loss: 0.104, kl: 62.049\n",
            "Epoch 2936\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 62.097\n",
            "\t[validation] loss: 0.101, rec loss: 0.101, kl: 62.046\n",
            "Epoch 2937\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 62.078\n",
            "\t[validation] loss: 0.109, rec loss: 0.109, kl: 62.078\n",
            "Epoch 2938\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 62.108\n",
            "\t[validation] loss: 0.100, rec loss: 0.100, kl: 62.055\n",
            "Epoch 2939\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 62.074\n",
            "\t[validation] loss: 0.094, rec loss: 0.094, kl: 61.999\n",
            "Epoch 2940\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 62.056\n",
            "\t[validation] loss: 0.097, rec loss: 0.097, kl: 62.020\n",
            "Epoch 2941\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 62.061\n",
            "\t[validation] loss: 0.096, rec loss: 0.096, kl: 62.048\n",
            "Epoch 2942\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.011, rec loss: 0.011, kl: 62.054\n",
            "\t[validation] loss: 0.095, rec loss: 0.095, kl: 62.022\n",
            "Epoch 2943\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.012, rec loss: 0.012, kl: 62.088\n",
            "\t[validation] loss: 0.091, rec loss: 0.091, kl: 62.033\n",
            "Epoch 2944\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.801, rec loss: 0.801, kl: 62.085\n",
            "\t[validation] loss: 1.049, rec loss: 1.049, kl: 62.467\n",
            "Epoch 2945\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.548, rec loss: 0.548, kl: 62.144\n",
            "\t[validation] loss: 0.201, rec loss: 0.201, kl: 61.962\n",
            "Epoch 2946\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.040, rec loss: 0.040, kl: 62.031\n",
            "\t[validation] loss: 0.140, rec loss: 0.140, kl: 62.008\n",
            "Epoch 2947\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.027, rec loss: 0.027, kl: 62.002\n",
            "\t[validation] loss: 0.129, rec loss: 0.129, kl: 61.930\n",
            "Epoch 2948\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.020, rec loss: 0.020, kl: 61.944\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 61.937\n",
            "Epoch 2949\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 61.942\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 61.934\n",
            "Epoch 2950\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 61.930\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 61.909\n",
            "Epoch 2951\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.961\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 61.949\n",
            "Epoch 2952\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.941\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 61.879\n",
            "Epoch 2953\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.884\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 61.875\n",
            "Epoch 2954\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.012, rec loss: 0.012, kl: 61.895\n",
            "\t[validation] loss: 0.098, rec loss: 0.098, kl: 61.860\n",
            "Epoch 2955\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.012, rec loss: 0.012, kl: 61.864\n",
            "\t[validation] loss: 0.100, rec loss: 0.100, kl: 61.848\n",
            "Epoch 2956\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.012, rec loss: 0.012, kl: 61.887\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 61.890\n",
            "Epoch 2957\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.012, rec loss: 0.012, kl: 61.907\n",
            "\t[validation] loss: 0.097, rec loss: 0.097, kl: 61.862\n",
            "Epoch 2958\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.011, rec loss: 0.011, kl: 61.894\n",
            "\t[validation] loss: 0.098, rec loss: 0.098, kl: 61.894\n",
            "Epoch 2959\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.011, rec loss: 0.011, kl: 61.950\n",
            "\t[validation] loss: 0.098, rec loss: 0.098, kl: 61.936\n",
            "Epoch 2960\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.924\n",
            "\t[validation] loss: 0.133, rec loss: 0.133, kl: 61.921\n",
            "Epoch 2961\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.392, rec loss: 1.392, kl: 61.998\n",
            "\t[validation] loss: 0.337, rec loss: 0.337, kl: 61.860\n",
            "Epoch 2962\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.076, rec loss: 0.076, kl: 61.771\n",
            "\t[validation] loss: 0.201, rec loss: 0.201, kl: 61.843\n",
            "Epoch 2963\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.036, rec loss: 0.036, kl: 61.844\n",
            "\t[validation] loss: 0.136, rec loss: 0.136, kl: 61.770\n",
            "Epoch 2964\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.025, rec loss: 0.025, kl: 61.828\n",
            "\t[validation] loss: 0.122, rec loss: 0.122, kl: 61.797\n",
            "Epoch 2965\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 61.817\n",
            "\t[validation] loss: 0.120, rec loss: 0.120, kl: 61.813\n",
            "Epoch 2966\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 61.816\n",
            "\t[validation] loss: 0.111, rec loss: 0.111, kl: 61.790\n",
            "Epoch 2967\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 61.798\n",
            "\t[validation] loss: 0.113, rec loss: 0.113, kl: 61.829\n",
            "Epoch 2968\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 61.827\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 61.807\n",
            "Epoch 2969\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.818\n",
            "\t[validation] loss: 0.101, rec loss: 0.101, kl: 61.785\n",
            "Epoch 2970\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.805\n",
            "\t[validation] loss: 0.107, rec loss: 0.107, kl: 61.811\n",
            "Epoch 2971\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.837\n",
            "\t[validation] loss: 0.097, rec loss: 0.097, kl: 61.820\n",
            "Epoch 2972\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.103, rec loss: 0.103, kl: 61.818\n",
            "\t[validation] loss: 2.653, rec loss: 2.653, kl: 61.903\n",
            "Epoch 2973\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 1.016, rec loss: 1.016, kl: 62.081\n",
            "\t[validation] loss: 0.198, rec loss: 0.198, kl: 61.899\n",
            "Epoch 2974\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.045, rec loss: 0.045, kl: 61.858\n",
            "\t[validation] loss: 0.139, rec loss: 0.139, kl: 61.813\n",
            "Epoch 2975\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.028, rec loss: 0.028, kl: 61.831\n",
            "\t[validation] loss: 0.129, rec loss: 0.129, kl: 61.830\n",
            "Epoch 2976\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.022, rec loss: 0.022, kl: 61.824\n",
            "\t[validation] loss: 0.118, rec loss: 0.118, kl: 61.847\n",
            "Epoch 2977\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 61.859\n",
            "\t[validation] loss: 0.114, rec loss: 0.114, kl: 61.861\n",
            "Epoch 2978\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.016, rec loss: 0.016, kl: 61.801\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 61.777\n",
            "Epoch 2979\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 61.798\n",
            "\t[validation] loss: 0.103, rec loss: 0.103, kl: 61.792\n",
            "Epoch 2980\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.800\n",
            "\t[validation] loss: 0.108, rec loss: 0.108, kl: 61.790\n",
            "Epoch 2981\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.827\n",
            "\t[validation] loss: 0.098, rec loss: 0.098, kl: 61.815\n",
            "Epoch 2982\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.821\n",
            "\t[validation] loss: 0.096, rec loss: 0.096, kl: 61.826\n",
            "Epoch 2983\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.837\n",
            "\t[validation] loss: 0.098, rec loss: 0.098, kl: 61.851\n",
            "Epoch 2984\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.884\n",
            "\t[validation] loss: 0.101, rec loss: 0.101, kl: 61.905\n",
            "Epoch 2985\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.012, rec loss: 0.012, kl: 61.906\n",
            "\t[validation] loss: 0.098, rec loss: 0.098, kl: 61.897\n",
            "Epoch 2986\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.012, rec loss: 0.012, kl: 61.910\n",
            "\t[validation] loss: 0.096, rec loss: 0.096, kl: 61.903\n",
            "Epoch 2987\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.952, rec loss: 0.952, kl: 62.001\n",
            "\t[validation] loss: 1.318, rec loss: 1.318, kl: 62.394\n",
            "Epoch 2988\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.254, rec loss: 0.254, kl: 62.260\n",
            "\t[validation] loss: 0.181, rec loss: 0.181, kl: 62.285\n",
            "Epoch 2989\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.035, rec loss: 0.035, kl: 62.116\n",
            "\t[validation] loss: 0.138, rec loss: 0.138, kl: 62.167\n",
            "Epoch 2990\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.024, rec loss: 0.024, kl: 62.085\n",
            "\t[validation] loss: 0.126, rec loss: 0.126, kl: 62.149\n",
            "Epoch 2991\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.018, rec loss: 0.018, kl: 62.053\n",
            "\t[validation] loss: 0.119, rec loss: 0.119, kl: 62.118\n",
            "Epoch 2992\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.017, rec loss: 0.017, kl: 62.055\n",
            "\t[validation] loss: 0.115, rec loss: 0.115, kl: 62.056\n",
            "Epoch 2993\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.015, rec loss: 0.015, kl: 62.000\n",
            "\t[validation] loss: 0.106, rec loss: 0.106, kl: 62.009\n",
            "Epoch 2994\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.013, rec loss: 0.013, kl: 61.969\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 62.033\n",
            "Epoch 2995\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.014, rec loss: 0.014, kl: 61.987\n",
            "\t[validation] loss: 0.102, rec loss: 0.102, kl: 62.034\n",
            "Epoch 2996\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.116, rec loss: 0.116, kl: 62.063\n",
            "\t[validation] loss: 0.401, rec loss: 0.401, kl: 62.360\n",
            "Epoch 2997\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.830, rec loss: 0.830, kl: 62.273\n",
            "\t[validation] loss: 0.175, rec loss: 0.175, kl: 62.119\n",
            "Epoch 2998\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.034, rec loss: 0.034, kl: 62.088\n",
            "\t[validation] loss: 0.139, rec loss: 0.139, kl: 62.082\n",
            "Epoch 2999\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.023, rec loss: 0.023, kl: 62.031\n",
            "\t[validation] loss: 0.122, rec loss: 0.122, kl: 62.008\n",
            "Epoch 3000\n",
            "\t[training] batches count: 79\n",
            "\t[training] loss: 0.019, rec loss: 0.019, kl: 61.996\n",
            "\t[validation] loss: 0.116, rec loss: 0.116, kl: 62.011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDNgmLT2Dywf"
      },
      "source": [
        "import results.analyse_results as my_analyse_results"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJdI6tqiDO2T",
        "outputId": "1fa052f9-441d-4b8a-efb5-0abf545988d7"
      },
      "source": [
        "stats = []\n",
        "epochs = list(range(50, 3001, 50))\n",
        "rec_file_template = '/content/drive/My Drive/exp_results_no_train_update/rec_%d'\n",
        "for t in epochs:\n",
        "    _, _, percent_correct = my_analyse_results.main(rec_file_template % t, TEST_FILE)\n",
        "    stats.append(percent_correct)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct formulas: 1506\n",
            "Incorrect formulas: 8494\n",
            "Percent of correct formulas: 15.060\n",
            "Correct formulas: 4523\n",
            "Incorrect formulas: 5477\n",
            "Percent of correct formulas: 45.230\n",
            "Correct formulas: 6414\n",
            "Incorrect formulas: 3586\n",
            "Percent of correct formulas: 64.140\n",
            "Correct formulas: 7256\n",
            "Incorrect formulas: 2744\n",
            "Percent of correct formulas: 72.560\n",
            "Correct formulas: 4962\n",
            "Incorrect formulas: 5038\n",
            "Percent of correct formulas: 49.620\n",
            "Correct formulas: 7487\n",
            "Incorrect formulas: 2513\n",
            "Percent of correct formulas: 74.870\n",
            "Correct formulas: 8313\n",
            "Incorrect formulas: 1687\n",
            "Percent of correct formulas: 83.130\n",
            "Correct formulas: 7094\n",
            "Incorrect formulas: 2906\n",
            "Percent of correct formulas: 70.940\n",
            "Correct formulas: 8526\n",
            "Incorrect formulas: 1474\n",
            "Percent of correct formulas: 85.260\n",
            "Correct formulas: 8056\n",
            "Incorrect formulas: 1944\n",
            "Percent of correct formulas: 80.560\n",
            "Correct formulas: 8926\n",
            "Incorrect formulas: 1074\n",
            "Percent of correct formulas: 89.260\n",
            "Correct formulas: 8051\n",
            "Incorrect formulas: 1949\n",
            "Percent of correct formulas: 80.510\n",
            "Correct formulas: 9064\n",
            "Incorrect formulas: 936\n",
            "Percent of correct formulas: 90.640\n",
            "Correct formulas: 8887\n",
            "Incorrect formulas: 1113\n",
            "Percent of correct formulas: 88.870\n",
            "Correct formulas: 8471\n",
            "Incorrect formulas: 1529\n",
            "Percent of correct formulas: 84.710\n",
            "Correct formulas: 9404\n",
            "Incorrect formulas: 596\n",
            "Percent of correct formulas: 94.040\n",
            "Correct formulas: 6789\n",
            "Incorrect formulas: 3211\n",
            "Percent of correct formulas: 67.890\n",
            "Correct formulas: 5987\n",
            "Incorrect formulas: 4013\n",
            "Percent of correct formulas: 59.870\n",
            "Correct formulas: 9433\n",
            "Incorrect formulas: 567\n",
            "Percent of correct formulas: 94.330\n",
            "Correct formulas: 9377\n",
            "Incorrect formulas: 623\n",
            "Percent of correct formulas: 93.770\n",
            "Correct formulas: 9554\n",
            "Incorrect formulas: 446\n",
            "Percent of correct formulas: 95.540\n",
            "Correct formulas: 9409\n",
            "Incorrect formulas: 591\n",
            "Percent of correct formulas: 94.090\n",
            "Correct formulas: 9527\n",
            "Incorrect formulas: 473\n",
            "Percent of correct formulas: 95.270\n",
            "Correct formulas: 7516\n",
            "Incorrect formulas: 2484\n",
            "Percent of correct formulas: 75.160\n",
            "Correct formulas: 7915\n",
            "Incorrect formulas: 2085\n",
            "Percent of correct formulas: 79.150\n",
            "Correct formulas: 9595\n",
            "Incorrect formulas: 405\n",
            "Percent of correct formulas: 95.950\n",
            "Correct formulas: 2976\n",
            "Incorrect formulas: 7024\n",
            "Percent of correct formulas: 29.760\n",
            "Correct formulas: 9622\n",
            "Incorrect formulas: 378\n",
            "Percent of correct formulas: 96.220\n",
            "Correct formulas: 8999\n",
            "Incorrect formulas: 1001\n",
            "Percent of correct formulas: 89.990\n",
            "Correct formulas: 9500\n",
            "Incorrect formulas: 500\n",
            "Percent of correct formulas: 95.000\n",
            "Correct formulas: 9661\n",
            "Incorrect formulas: 339\n",
            "Percent of correct formulas: 96.610\n",
            "Correct formulas: 9595\n",
            "Incorrect formulas: 405\n",
            "Percent of correct formulas: 95.950\n",
            "Correct formulas: 9678\n",
            "Incorrect formulas: 322\n",
            "Percent of correct formulas: 96.780\n",
            "Correct formulas: 9412\n",
            "Incorrect formulas: 588\n",
            "Percent of correct formulas: 94.120\n",
            "Correct formulas: 9673\n",
            "Incorrect formulas: 327\n",
            "Percent of correct formulas: 96.730\n",
            "Correct formulas: 9674\n",
            "Incorrect formulas: 326\n",
            "Percent of correct formulas: 96.740\n",
            "Correct formulas: 7008\n",
            "Incorrect formulas: 2992\n",
            "Percent of correct formulas: 70.080\n",
            "Correct formulas: 9688\n",
            "Incorrect formulas: 312\n",
            "Percent of correct formulas: 96.880\n",
            "Correct formulas: 9640\n",
            "Incorrect formulas: 360\n",
            "Percent of correct formulas: 96.400\n",
            "Correct formulas: 9299\n",
            "Incorrect formulas: 701\n",
            "Percent of correct formulas: 92.990\n",
            "Correct formulas: 9679\n",
            "Incorrect formulas: 321\n",
            "Percent of correct formulas: 96.790\n",
            "Correct formulas: 9645\n",
            "Incorrect formulas: 355\n",
            "Percent of correct formulas: 96.450\n",
            "Correct formulas: 9473\n",
            "Incorrect formulas: 527\n",
            "Percent of correct formulas: 94.730\n",
            "Correct formulas: 9687\n",
            "Incorrect formulas: 313\n",
            "Percent of correct formulas: 96.870\n",
            "Correct formulas: 9637\n",
            "Incorrect formulas: 363\n",
            "Percent of correct formulas: 96.370\n",
            "Correct formulas: 9683\n",
            "Incorrect formulas: 317\n",
            "Percent of correct formulas: 96.830\n",
            "Correct formulas: 9672\n",
            "Incorrect formulas: 328\n",
            "Percent of correct formulas: 96.720\n",
            "Correct formulas: 9664\n",
            "Incorrect formulas: 336\n",
            "Percent of correct formulas: 96.640\n",
            "Correct formulas: 9697\n",
            "Incorrect formulas: 303\n",
            "Percent of correct formulas: 96.970\n",
            "Correct formulas: 5260\n",
            "Incorrect formulas: 4740\n",
            "Percent of correct formulas: 52.600\n",
            "Correct formulas: 9635\n",
            "Incorrect formulas: 365\n",
            "Percent of correct formulas: 96.350\n",
            "Correct formulas: 9691\n",
            "Incorrect formulas: 309\n",
            "Percent of correct formulas: 96.910\n",
            "Correct formulas: 9496\n",
            "Incorrect formulas: 504\n",
            "Percent of correct formulas: 94.960\n",
            "Correct formulas: 9216\n",
            "Incorrect formulas: 784\n",
            "Percent of correct formulas: 92.160\n",
            "Correct formulas: 9635\n",
            "Incorrect formulas: 365\n",
            "Percent of correct formulas: 96.350\n",
            "Correct formulas: 9634\n",
            "Incorrect formulas: 366\n",
            "Percent of correct formulas: 96.340\n",
            "Correct formulas: 9664\n",
            "Incorrect formulas: 336\n",
            "Percent of correct formulas: 96.640\n",
            "Correct formulas: 5646\n",
            "Incorrect formulas: 4354\n",
            "Percent of correct formulas: 56.460\n",
            "Correct formulas: 9660\n",
            "Incorrect formulas: 340\n",
            "Percent of correct formulas: 96.600\n",
            "Correct formulas: 9637\n",
            "Incorrect formulas: 363\n",
            "Percent of correct formulas: 96.370\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBgBqK6g4f4E"
      },
      "source": [
        " import matplotlib.pyplot as plt"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "t-27Fq3IEKTB",
        "outputId": "96ffbddf-2f20-4a24-fde5-0ae48546497b"
      },
      "source": [
        "f = plt.figure(figsize=(15, 7), dpi=100)\n",
        "plt.plot(epochs, stats, marker='o')\n",
        "plt.title(\"\"\"\n",
        "Percent of correct formulas on test dataset based on the number of epochs.\n",
        "Train size: 20000, Test size: 10000.\n",
        "Formulas: a0 + a1*x + a2*x^2 + a3*x^3 + a4*x^4 + a5*x^5, ai in {0, 1, ..., 49}.\n",
        "No intersections in Train and Test sets\n",
        "\"\"\")\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Percent of correct formulas')\n",
        "# plt.legend()\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.savefig('no_train_update.png', dpi=f.dpi)\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1500x700 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0RytIeGEKVo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plr6RpMMEKX-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AqwkPJREKan"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHPvVG6sEKda"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKIXUOOgEKgA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD3p8aACoyBD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}